# AI レッド チーム演習のプロバイダー＆ツールのベンダーを評価するための基準

- バージョン 1.0 ー 公式リリース 2026/2/13

-------------------------------------------------

${toc}

-------------------------------------------------
# 1. 概要

ほとんどの組織は、チャット ボット、カスタマー サポート アシスタント、ワークフロー コパイロット、基本的な RAG アプリケーションなどの単純な生成 AI システムを導入しています。ツール呼び出しエージェント、MCP ベースのアーキテクチャ、マルチ エージェント ワークフローなどの高度な AI システムを運用する組織は少数ながら増加しています。

どちらのカテゴリも、専門的な敵対的評価を必要とするリスクをもたらします。多くのベンダーは、表面的な脱獄のデモや静的なプロンプト ライブラリに焦点を当て、システムの脆弱性、ワークフローの迂回、悪用のリスク、エージェントまたはツール対応システムの障害を無視することで、過剰な主張をしています。

本書では、AI レッド チーム演習コンサルティング サービスと自動化ツールのベンダーを評価するための基準を示し、単純な生成 AI と高度な 生成AI の両方のデプロイメントにおける考慮事項を取り上げています。本書では、以下の点に焦点を当てています。

- 効果的な AI レッド チーム演習とは
- ベンダーにどのような質問をすべきか
- 能力を示す「グリーン フラグ」とは
- 低品質または誤解を招く可能性のあるサービスを示す「レッド フラグ」とは
- 真の敵対的評価と表面的なテストを区別する方法

目標は、ビジネス リーダーや経営幹部が、単なるカバー範囲の錯覚を提供するプロバイダーではなく、真のリスクを軽減するプロバイダーを自信を持って特定できるようにすることです。

## 1.1. クイック エグゼクティブ ガイド: グリーン フラグとレッド フラグ

ここでは、パートナーシップを検討しているベンダーの能力レベルを迅速に判断するためのガイドとして、非常に高レベルの項目をいくつか紹介します。

### ✅ グリーン フラグ

- 再現可能なシングル ターンおよびマルチ ターンの敵対的評価を実施している
- 公開データベースからの脱獄の再利用ではなく、新しい知見に基づくカスタム テストを実施している
- 事業影響度マッピングを含む明確なレポートを実施している
- 単純なシステムから高度なシステムまで、実証済みの能力と経験がある
- 重要な知見の人間による検証を実施している
- 記憶、長期セッション、セッション間動作を含むステートフル システムの評価能力がある
- 調査結果から実用的な改善ガイダンスを導出している

### 🚫 レッド フラグ

- レッド チーム演習と称して、既存の脱獄ライブラリを使用している
- ベンダーが、最新のアーキテクチャ（RAG、メモリなど）、プロトコル（MCP、A2A、ACP）、メソッド（微調整、ツール呼び出し）の仕組みを明確に説明できない
- マルチ ターン テストやステートフル テスト機能がない
- 人間による監視なしに AI が評価を生成している
- 「完全なカバレッジ」やワン クリックのレッド チーム演習を謳っている
- モデルの出力のみに焦点を当て、アクション、システム状態の変化、実際の影響を無視している
- 機能テストが不足している
- 方法論やテスト設計の透明性が欠如したブラックボックス スコアリングを実施している
- 使用事例に固有のカスタマイズされた評価がなく、顧客の実際のワークフロー、データ、ビジネス ロジックへの適応が欠如している


# 2. 背景と定義

## 2.1. AI レッド チーミング演習とは何か？（そうではないものは何か）

本書では、AI レッド チーム演習とは、AI システムの安全性、セキュリティ、悪用、堅牢性、倫理性、およびアライメントの障害モードを明らかにするための敵対的テストと定義されます。これには、シングル ターンおよびマルチ ターンのプロービング、ワークフローの悪用、システムの迂回、シナリオ ベースの悪用の検出が含まれます。

本書は、AI を使用してインフラストラクチャ、ネットワーク、Web アプリ、またはソーシャル エンジニアリングの従来のレッド チーム演習を実行するベンダーを対象として**いません**。AI モデルおよび AI システムのレッド チーム演習を実行するサービスを提供するベンダーにのみ焦点を当てています。

## 2.2. 本書で網羅されているシステムの種類

### 単純な生成 AI システム

環境は急速に進化していますが、今日ではこれらの単純なシステムが最も一般的にデプロイされています。単純なシステムには、以下のようなものがあります。

- カスタマー サポート チャットボット
- 社内 LLM コパイロット（人事、IT、財務、営業）
- ワークフロー アシスタント
- FAQ/ナレッジベース ボット
- RAG システムおよび検索ベースの質問応答
- タスク固有のシングル ターンまたはマルチ ターンの会話エージェント
- 思考連鎖（CoT）に基づく推論機能を備えたチャットまたはエージェント

一般的なリスクには、脱獄、有害コンテンツ、幻覚、漏洩、内部データの悪用、一貫性のない行動、ペルソナ操作などがあります。


### 高度な生成 AI システム

エンタープライズ グレードのソリューションでますます一般的になり、急速に拡張されている高度なシステムには、以下が含まれます。

- ネイティブ ツール呼び出し機能（OpenAI、Anthropic、ReAct、カスタム スキーマ）
- MCP（モデル コンテキスト プロトコル）を介してツールを公開するシステム
- マルチ エージェント オーケストレーション
- マルチ エージェント コラボレーション（例： A2A (Agent2Agent) プロトコル経由）
- ロール ベースまたは自律型エージェント
- 下流のアクションを実行する連鎖ワークフロー
- ストリーミング サービス (Redis)、永続データベース (MongoDB、CosmoDB)、および/またはベクトル データベース (Pinecone、Weaviate) に基づく記憶の実装
- 可観測性と監視の統合 (Datadog、Langfuse、MLFlow)
- 実運用のための LLM 統合自動化

一般的なリスクには、安全でないツールの実行、ラグ プル攻撃、ツール シャドウイング、機能エスカレーション、エージェント間汚染、メッセージ パッシングの脆弱性、記憶およびコンテキスト汚染、データの意図せぬ公開、データ汚染、データ持ち出し、ユーザーをソーシャル エンジニアリングするための出力制御、制御推論、および創発的な動作の障害などがあります。

## 2.3. 典型的な対象

- 基盤モデル（テキスト、マルチモーダル）
- 微調整されたエンタープライズ モデル（ドメイン適応型、指示調整型、RLHF 学習型）
- チャット ボットとドメイン コパイロット
- RAG システムと検索チェーン
- エージェントが利用できるデータベース、またはチャットログを保存するデータベース
- エージェント型システム: 単一エージェント、マルチ エージェント、ロールベース オーケストレーター
- MCP ベースのツール レジストリ
- ツール呼び出しのワークフロー
- LLM 対応の自律型ワークフロー
  
## 2.4. ベンダーの種類

| ベンダーの種類 | 説明 |
| ----- | ----- |
| **チャットボット/基本的な LLM レッド チーム演習スペシャリスト** | これらのベンダーは、通常、脱獄の検出、安全性の問題、幻覚ストレス テスト、ドメイン固有の悪用といった問題について、より単純な LLM アプリケーションをテストします。複雑なシステムの動作ではなく、モデル/アプリケーション層の相互作用に焦点を当てています。|
| **AI レッドチーム コンサルタント** | 複雑で多段階的な検出、脅威モデリング、創発的な動作の分析、そして詳細なアーキテクチャ テストに熟練した人間の敵対者です。新しい攻撃の検出、複雑なマルチ エージェント システム分析、カスタム脅威モデリングを必要とする、高度な AI システムや高リスクなデプロイメントのテストに適しています。 |
| **AI レッド チーム演習自動化ツール** | これらのツールは、プロンプト ライブラリ、シナリオのバリエーション、エージェント/ツール呼び出しワークフロー、MCP テストなど、大規模な敵対的テスト スイートの実行を可能にします。多くの場合、これらは CI/CD パイプラインを対象とし、24 時間 365 日の継続的なテストと長期的なパフォーマンスのマッピングを実現します。 |

# 3. 詳細な評価基準

このセクションでは、特に最新の AI セキュリティの課題に焦点を当てて、ベンダー評価における重要なカテゴリを概説します。

必要に応じて、各カテゴリには、単純なシステムと高度なシステムの基準が含まれており、レッド フラグ（より詳細な調査を必要とする指標）とグリーン フラグ（ベンダーの価値の可能性を示す指標）の両方が含まれています。

## 3.1. 技術的能力

### 単純な生成 AI システム

ベンダーは、以下の専門知識を実証する必要があります。

- 脱獄およびポリシー回避パターン
- プロンプト インジェクションおよび間接プロンプト インジェクション
- マルチ ターンの欺瞞およびペルソナ ベース攻撃
- 漏洩リスク（機密データ、規制対象データ）
- RAG 固有の攻撃対象領域（検索オーバーライド、セマンティック ハイジャック）
- 反復的な敵対的ストレス下における安全性の動作

#### 🚫 レッド フラグ

- ベンダーは、公開の脱獄データベースまたは些細な「プロンプト トリック」のみに依存しています。

#### ✅ グリーン フラグ

- ベンダーは、顧客のシステムに特化した、斬新な攻撃戦略とマルチ ターン敵対的推論を備えたカスタム敵対的テストを開発しています。

### 高度な生成 AI システム

ベンダーは、以下の点について深い理解を示す必要があります。

- ツール呼び出しのセマンティクス、スキーマ操作、安全でないツール呼び出しのトリガー
- マルチ モーダル攻撃: クロス モーダル プロンプト インジェクションと安全性の不整合
- MCP 内部：ツールの意図せぬ公開、機能の登録、サンドボックス境界
- マルチ エージェント アーキテクチャ: メッセージ パッシング、ロール汚染、創発的な動作
- 連鎖コンポーネント間のステートフルなマルチ ターン インタラクション
- ツールとエージェントを介した権限昇格経路
- エージェントの内部防御をテストすることを目的とした、信頼できない様々なソース フィールドへの間接プロンプト インジェクション
- キル スイッチの信頼性をテストすることを目的とした、人間による介入の迂回

#### 🚫 レッド フラグ

- ベンダーは、MCP、ツール呼び出し、またはマルチ エージェント システムを単純なチャットボットとして扱っています。
- ベンダーは、安全でないツール スキーマ、エージェント ロールのドリフト、または機能の過剰露出によるリスクを明確に説明できません。
- ベンダーは、サンドボックス環境内でエージェントによるコマンドまたはコード実行を、サンドボックスを脱出することなく実証しています。
- ベンダーは、「不正なアクション」が AI エージェントの予期される機能であるにもかかわらず、バグとして識別しています。

#### ✅ グリーン フラグ

- ベンダーは、マルチ エージェント生成 AI システムの複雑さを理解しています。
- ベンダーは、安全でないツール呼び出しの経路、エージェントの創発的な動作、およびエージェント間の汚染をテストした実践経験があります。

## 3.2. 方法論と網羅性


### 単純な生成 AI システム

以下の項目を網羅することが期待されます。

- 堅牢な脱獄試行
- 毒性、バイアス、有害コンテンツの生成
- RAG 信頼性および敵対的検索攻撃
- 機密情報の抽出
- 幻覚リスクの評価
- ユーザー リクエストへの過度の信頼と安全でないコンプライアンス

#### 🚫 レッド フラグ

- ベンダーは、ドメイン適応や顧客のデータ、ポリシー、使用事例へのカスタマイズを伴わない、汎用的な「脱獄テスト パック」を提供しています。
- ベンダーは、攻撃の根拠や、ワークフローや脅威モデルにとって特定のテストがなぜ重要なのかを説明できません。
- ベンダーは、システムのアーキテクチャやデータフローに明確に結び付けられていない、汎用的な調査結果を提供しています。

#### ✅ グリーン フラグ

- ベンダーは、顧客の特定の業界や使用事例に合わせてテストをカスタマイズする方法を示しています。
- ベンダーは、システムの応答に基づいて進化する反復的な適応型テストを実施できることを実証しています。
- ベンダーは、基本的な脱獄を超えた特定の攻撃手法とペイロードに関する知識（ポリシー回避、潜在的命令抽出、データ汚染、ゴールの乗っ取り、思考連鎖操作など）を実証しています。

### 高度な生成 AI システム

ベンダーのアプローチは、以下のような幅広い高度な攻撃クラスを網羅する必要があります。

- ツール呼び出しの悪用テスト（不正なツール呼び出し、スキーマ操作、および安全でないツールの動作の攻撃者によるトリガー）
- スキーマおよびパラメータの操作
- MCP による安全でない機能の露出（機能の悪用、過剰なサンドボックス化／サンドボックス化が不十分なツール、および誤って登録されたツールによる権限昇格）
- マルチ エージェント汚染または強制
- エージェント間汚染、調整の失敗、出現する敵対的戦略、およびロールの漏洩
- 創発的な戦略の発見
- 複数ステップの敵対的ワークフロー

#### 🚫 レッド フラグ
- ベンダーは、モデル出力のみを評価し、ツール呼び出しの動作を無視しています。
- ベンダーは、マルチ エージェント攻撃を主張しているが、メッセージ パッシング操作やロール汚染攻撃を実証できていません。

#### ✅ グリーン フラグ

- ベンダーは、個々の出力だけでなく、インタラクションとワークフローをテストしています。
- ベンダーは、現実的な脅威アクターを反映した、複数段階の攻撃ワークフローを実装しています。
- ベンダーは、安全でないフォールバック動作を特定するために、エラー、タイムアウト、エッジケースを意図的にトリガーしています。

## 3.3. 敵対的な創造性とドメイン専門性

### 共通

- **コンサルタント**は、特にツールや複数のエージェントを巻き込んだ、**斬新な**敵対的攻撃戦略と複雑な多段階攻撃チェーンを構築する能力を実証する必要があります。
• **自動化ツール**は、攻撃生成の多様性、適応性（静的なテンプレートではない）、およびマルチ ターン、マルチ エージェント シミュレーション機能に基づいて評価する必要があります。


### 単純な生成 AI システム

ベンダーは、以下の点を実証する必要があります。

- 敵対的ペルソナの作成
- 顧客のビジネス ドメインおよび使用事例に関連する悪用シナリオのシミュレーション
- 複数ターンにわたるエスカレーション戦略
- 既存の脱獄ライブラリにない新しい攻撃クラス

#### 🚫 レッド フラグ

- ベンダーは、新しいコンテンツやエスカレーション ロジックのない既存の脱獄ライブラリを使用しています。
- ベンダーは、敵対的ペルソナを顧客のドメイン リスクにマッピングできていません。

#### ✅ グリーン フラグ

 - ベンダーは、現実的なマルチ ターンにわたる敵対的ペルソナと、ドメインに関連する悪用シナリオを作成しています。

### 高度な生成 AI システム
以下の点において創造性が求められます。

- ツールとエージェントをまたがる複雑な攻撃チェーンの構築
- ツールの悪用を誘発する巧妙なトリガーの作成
- エージェントの連携に関する想定への攻撃

#### 🚫 レッド フラグ

- ベンダーは、ツール、エージェント、ステートフル コンポーネントにまたがる敵対的チェーンを設計できません。
- ベンダーは、エージェントを、創発的なダイナミクスを持つシステムではなく、独立したコンポーネントとしてテストしています。

#### ✅ グリーン フラグ

- ベンダーは、複数段階のマルチ エージェント攻撃チェーンと、ツールの悪用を誘発する巧妙なトリガーを構築しています。

強力なベンダーは、単純なシステムから高度なシステムまで、継続的な研究意識を示し、最新の学術研究や業界研究から新たに発見された生成 AI 攻撃手法を取り入れながら、敵対的テストのアプローチを継続的に進化させています。

## 3.4. 脅威モデリングの現実性

脅威モデルは、単純な脱獄シナリオを超えてシステム障害にまで拡張する必要があり、以下を含める必要があります。

### 単純な生成 AI システム

- 有害なコンテンツの生成
- トピック外の応答
- システム プロンプトの開示
- ビジネスまたは風評に損害を与える幻覚
- 機密データまたは内部データの漏洩
- プロンプト操作によるワークフローの迂回
- 危険な指示や誤った指示への過剰な準拠

#### 🚫 レッド フラグ
- 脅威モデルは「LLM 脱獄のみ」です。
- ベンダーは、幻覚を運用上の危険ではなく表面的な問題として扱っています。

#### ✅ グリーン フラグ

- 脅威モデルは、データ、ワークフロー、および障害モードを含む現実的なビジネスへの影響シナリオを捉えています。
- ユーザー認証などの機密タスクに AI モデルを使用することに伴うセキュリティ リスクを強調しています。
- クロスサイト スクリプティングなどの攻撃を防ぐための入出力の無害化の重要性を考慮しています。

### 高度な生成 AI システム

- ツールの悪用または破壊的なツール呼び出しのトリガー
- MCP 機能のエスカレーションまたは安全でない露出
- エージェント境界の侵害
- 思考連鎖の漏洩
- エージェント間の敵対的な創発的行動

#### 🚫 レッド フラグ

- ベンダーは、ツールの悪用を無視しているか、ツールの出力が本質的に安全であると想定しています。
- ベンダーは、エージェント境界の侵害やエージェント間の創発的動作をテストしていません。
- ベンダーは、モデル レベルのテストに重点を置き、システム レベルの動作や相互作用を無視しています。

#### ✅ グリーン フラグ

- 脅威モデルは、ツール呼び出しの悪用、安全でない機能の露出、敵対的な戦略の出現といったシステム リスクを網羅しています。
- 脅威モデルは、自律型 AI による機密性の高いアクションの悪用を防ぐことを目的とした、人間が関与するガードレールが不足していることに対処しています。


## 3.5. 評価の厳密さと指標

評価は、明確性、一貫性、再現性、そして現実世界のリスクに結びついた重大度評価に重点を置く必要があります。ベンダーは、独自の不透明で独自の方法論よりも、確立された指標と透明性のあるベンチマークを優先する必要があります。特定の領域ではエラーに対する許容度が低い場合があるため（例: 医療データが関係する場合）、結果を解釈するにはコンテキストが重要です。

### 単純な生成 AI システム

パフォーマンス指標には、幻覚などの技術的障害をビジネス リスクに結び付けるために、マーケティングではなく研究に基づいた一貫した定義が必要です。指標は、単発の結果に頼るのではなく、同じ攻撃の複数回の試行、プロンプトの連鎖、思考の連鎖を考慮する必要があります。RAG システムでは、指標は情報検索の仕組みに基づいている必要があります。以下の指標が期待されます。

- 脱獄成功率
- 安全ガードレールの迂回率
- 幻覚の頻度と深刻度
- 漏洩量と機密度レベル
- 敵対的負荷下における RAG 検索の信頼性

#### 🚫 レッド フラグ

- ベンダーは、再現可能な指標を提示せずに、定性的な「雰囲気に基づく」スコアリングを提供しています。
- ベンダーは、深刻度が現実世界への影響とどのように関連しているかを示すことができません。
- ベンダーは、正解率、適合率、再現率などの指標の違いを明確に説明できません。
- ベンダーは、正解率に依存しており、稀な攻撃における失敗を隠蔽しています。
- ベンダーは、単発攻撃プロンプトの静的なリストを使用しており、可変性に欠け、幸運なヒットに頼っています。
- ベンダーは、長い会話型攻撃、文書によるインジェクション、文書汚染、その他高度な生成 AI インタラクションを実行するためのツールを持っていません。
- ベンダーは、ベンチマークの詳細や手法を公開していません。
- ベンチマークがコンテキストと一致していません。

#### ✅ グリーン フラグ

- 指標は、定量的で、再現性があり、重要なリスクに結びついています。
- ベンダーは、様々なパフォーマンス指標や混同行列を提供します。
- ベンダーは、顧客のビジネス リスクに合わせた最適な指標を推奨しています。
- ベンダーは、顧客と協力して、ドメイン固有のリスク許容しきい値を定義しています。
- ベンダーは、技術的な障害とポリシー違反を区別しています。
- ベンダーは、生成 AI システムの複雑さに対応する最先端の指標を報告します。以下は、その指標の例です。
	- **pass@k**: k 回の独立した試行における攻撃成功確率を測定します。
	- **平均脱獄回数**: システムが破られるまでに耐えられる深さを追跡します。
	- **平均リスク密度**: 思考連鎖コンテンツが攻撃者に公開されている場合における、有害なトークンとすべての推論トークンの比率の平均。
	- **取得成功率 (RSR@k)**: RAG に挿入された悪意のあるコンテンツが、セマンティック検索と再ランク付けによって正常に取得される頻度を測定します。

### 高度な生成 AI システム

指標では、単純なテキスト入出力ではなく、複雑なアーキテクチャ設計パターンを評価します。以下の指標が期待されます。

- ツールの誤作動の頻度
- 敵対的負荷下における安全でないツール呼び出し率
- MCP 機能の悪用の網羅度
- マルチ エージェントの汚染率
- 調整の崩壊の深刻度

#### 🚫 レッド フラグ

- ベンダーは、複雑な創発的動作について、人間による検証なしに AI 判定を使用しています。
- 指標は、連鎖的なツールの悪用などのシステム的な障害を無視しています。

#### ✅ グリーン フラグ

- ベンダーは、多層測定<span style="font-size: small">（訳者注: 原文では instrumentation）</span>を用いた構造化され再現可能な評価を提示しています。
- ベンダーは、評価フェーズ中に破壊的なツール呼び出しを安全にテストするために、サンドボックス化された実行環境を利用しています。
- ベンダーは、エージェントが攻撃者の利益のために正規のツール（例: send_email または query_database）を使用するように仕向けるテストを実証しています。
- ベンダーは、「垂直権限昇格」のテストを実施しています。これは、「ユーザー」権限を持つエージェントが
「管理者」レベルのツール呼び出しを実行するように操作されるものです。
- ベンダーは、複数段階のツール不正利用チェーンをテストしています（例: ステップ 1: search_wiki を使用して CEO の経歴を検索。ステップ 2: draft_email を使用して CEO になりすます。ステップ 3: send_invoice を使用して資金を盗む）。


## 3.6. ツールとインフラストラクチャの品質

ベンダーは、実際の環境でのテストをサポートし、次のことを実証する必要があります。

### 単純な生成 AI システム

- マルチ ターンのログ記録
- 安全性動作の追跡
- RAG イントロスペクション（内省）
- シナリオ リプレイ
- 詳細なメッセージ パスのログ記録
- マルチ ターン オーケストレーションによる評価を実行する能力

#### 🚫 レッド フラグ

- ベンダーは、マルチ ターン インタラクションを再現できず、完全なログ記録が不足しています。
- リプレイまたはイントロスペクションの仕組みがありません。

#### ✅ グリーン フラグ

- ベンダーは、シナリオ リプレイ、メッセージ パスのログ記録、およびマルチ ターン オーケストレーションをサポートしています。

### 高度な生成 AI システム

- 呼び出しのリプレイとイントロスペクション
- MCP 測定<span style="font-size: small">（訳者注: 原文では instrumentation）</span>と機能トレース
- マルチ エージェント シミュレーション環境
- 可観測性機能（エージェント メッセージの追跡、ツール呼び出しタイムライン、再現のための詳細ログ）
- マルチ ターン オーケストレーションによる評価を実行する能力

#### 🚫 レッドフラグ：

- ベンダーは、ツール呼び出しをイントロスペクションのない不透明なイベントとして扱っています。
- マルチ エージェント シミュレーションがないか、エージェント間のメッセージフローをトレースできません。

#### ✅ グリーン フラグ

- ベンダーは、ツール呼び出しのリプレイ、MCP<span style="font-size: small">（訳者注: 原文では instrumentation）</span>、エージェント トレース ログ、そして堅牢な可観測性を提供しています。

## 3.7. データ ガバナンスとセキュリティ

ベンダーは、ログ、プロンプト、および出力のデータの取り扱い、保持、および削除に関するアプローチを明確に示す必要があります。以下の点を評価してください。

- プロンプト、ログ、および出力の保存方法
- 機密性の高い運用データの分離方法
- エージェント ツールのアクセス制御ポリシー
- ツール アクセス データの保護
- モデルの重みまたはアプリケーション シークレットに対する要件
- オンプレミスまたはセルフ ホスティング オプションの可用性
- チーム/ツールが利用する AI プロバイダーに対してベンダーが実施しているゼロ データ保持ポリシー

#### 🚫 レッド フラグ

- ベンダーは、保持モデルまたはデータ分離モデルを説明できません。
- ベンダーは、共有テスト環境で本番環境のシークレットまたは顧客データを使用しています。
- ベンダーは、どのサードパーティー AI プロバイダーがデータを受け取っているか開示を拒否しています。

#### ✅ グリーン フラグ

- ベンダーは、ゼロデータ保持またはオンプレミス オプション、明確なアクセス制御、分離されたテスト環境を提供しています。
- ログとアーティファクトは、厳格なライフサイクル ポリシーに基づいてスクラビングまたは暗号化されています。

## 3.8. 透明性と説明可能性

ベンダーは、以下の情報を提供する必要があります。

- 明確な段階的な攻撃チェーン
- ツール呼び出しの出所
- MCP 機能エスカレーション図
- マルチ エージェントのメッセージとアクションのトレース
- テスターのアクションと観測されたモデル/エージェントの動作を明確に区別し、すべての主張を裏付ける生の証拠を提示
• AI システムのデフォルト構成を変更するような、対象システムに加えられた構成変更の詳細

#### 🚫 レッド フラグ

- ベンダーは、「脱獄のスクリーンショット」のみを提供し、その実現方法を示していません。
- ベンダーは、自身の推論とモデルの動作を区別できていません。

#### ✅ グリーン フラグ

- 段階的な攻撃チェーン、機能の出所、および完全なメッセージ/ツール呼び出しのトレース。
- MCP またはエージェントのインタラクション構造を示す明確な図。

## 3.9. カスタマイズと適応性

ベンダーは、以下の要件に合わせてテストをカスタマイズできる能力を示す必要があります。

- 顧客のデータ ドメイン
- 顧客のワークフロー
- 顧客のツール スタックと MCP レジストリ
- 顧客のカスタム脅威モデル
- 顧客のポリシーとコンプライアンス要件

#### 🚫 レッド フラグ
- ベンダーは、すべてのクライアントに同一のテストスイートを適用しています。
- ベンダーには、顧客のワークフロー、ツール、またはドメインをテスト シナリオに組み込む能力がありません。
- ベンダーは、AI システムへの単純な接続オプションのみをサポートしています（例: 単一の推論エンドポイント
と単純なトークン ベースの認証戦略など）。

#### ✅ グリーン フラグ

- テストは、顧客のドメイン、ワークフロー、ツール、およびポリシーに適合しています。
- ベンダーは、顧客のシステムの進化に合わせて方法論を調整しています。

## 3.10. 運用適合性/統合

ベンダーは、以下をサポートしている必要があります。

- CI/CD 統合（特に継続的なレッド チーム演習と自動回帰テスト用）
- 継続的な回帰テスト
- 破壊的データや機密データを扱うツールの使用に適した安全なサンドボックス
- 本番環境と同様のワークフローの評価
- SaaS、オンプレミス、ハイブリッド環境を含む複数のデプロイメント モデル
- 異なるクラウド プロバイダーやマルチ クラウド環境での運用
- 複数の LLM プロバイダーおよびデプロイメント オプションとの互換性

#### 🚫 レッド フラグ

- ベンダーは、CI/CD との統合や回帰テストを提供できません。
- ベンダーは、テスト実行のために社内システムまたはデータを自社環境にエクスポートする必要があります。

#### ✅ グリーン フラグ

- ベンダーは、サンドボックス テスト、ワークフロー レベルの評価、自動回帰サイクルをサポートしています。
- ツールは、ビルド パイプラインまたはモデルガバナンス ワークフローと統合されています。

## 3.11. 既知の制限とバイアス

ベンダーは、以下の点を含め、自社の限界について透明性を確保する必要があります。

- 網羅の対象外としている事項
- 自動化の限界
- 創発的な動作の検出における盲点
- LLM を判断基準とするスコアリングへの過度の依存のリスク
- MCP またはツール呼び出しを本質的に安全であるとみなすこと

#### 🚫 レッド フラグ
- ベンダーは、「完全な網羅性」を主張している、またはすべての創発的な動作を検出できると示唆しています。
- ベンダーは、文書化された限界を開示していない、または盲点の開示を拒否しています。
- ベンダーは、LLM を判断基準とするスコアリングに関連するリスクを否定しています。

#### ✅ グリーン フラグ

- ベンダーは、何が範囲外か、自動化が失敗する箇所、そして人間の専門知識がどのように適用されるかを明確に文書化しています。
- ベンダーは、不確実性とエッジ ケースの網羅限界についてオープンに説明しています。

## 3.12. コスト対価値

意思決定者は、以下の点を評価する必要があります。

- 調査結果が実際のリスクを軽減しているか否か
- レポートは実行可能か否か
- 自動化によってコストが相殺されているか否か
- 必要に応じて人間の創造性が活用されているか否か

#### 🚫 レッド フラグ

- 価格は高いのに、調査結果は一般的、実行不可能、または価値が低いものとなっています。
- ベンダーは、意味のあるリスク軽減よりもテストの量を重視しています。

#### ✅ グリーン フラグ

- コストは、測定可能なリスク軽減策、明確なレポート、優先順位付けされた改善ガイダンスと相関しています。
- 自動化によって、人間の敵対的な創造性を排除することなく、コストと労働時間を大幅に削減できています。

## 3.13. 法的、倫理的、コンプライアンス態勢

以下の要件との整合性と理解が求められます。

- OWASP AI Security & Safety Guide
- NIST AI RMF
- MITRE Atlas
- ISO 42001 / 23894
- EU AI Act
- Google Secure AI Framework (SAIF)

おそらく最も重要なことは、ベンダーが顧客の内部ガバナンス要件、現地の規制、その他の固有のニーズに対応できることを確認することです。

#### 🚫 レッド フラグ

- ベンダーは、安全なテストの規範を無視しています（例: 承認されたサンドボックス外での破壊的な操作）。
- ベンダーは、OWASP、NIST AI RMF、ISO 42001/23894 などのコア フレームワークや顧客の内部ガバナンスに自社のアプローチをマッピングできていません。
- ベンダーは、新たな規制要件（EU AI Act、各国の AI 安全性協会のガイダンス、または顧客の地域に関連するその他の規制）を認識していない、または無視しています。
- ベンダーは、AI レッド チーム演習を法的、倫理的、またはリスク管理上の義務に対処せずに、純粋に技術的な問題として扱っています。
- ベンダーは、適切な承認なしにテストを実施しているか、明確なエンゲージメント ルールを欠いています。
- ベンダーは、調査結果が実際のコンプライアンス要件、リスク階層、またはガバナンス構造とどのように関連しているかを説明できません。

#### ✅ グリーン フラッグ

- ベンダーは、OWASP、NIST AI RMF、MITRE ATLAS、ISO 42001、ISO 23894、および最新の AI 安全性協会のガイダンスに精通していることを示しています。
- ベンダーは、規制上の影響（EU AI Act など）を理解し、これらのフレームワーク内で調査結果を文脈化できます。
- ベンダーは、すべてのテスト活動に対して明確なスコープ、承認フロー、および安全管理策を提供しています。
- ベンダーは、自社の手法を内部ガバナンス、リスク階層、データポリシー、およびモデル/ツールスタックに適合させています。
- ベンダーは、調査結果と確立されたフレームワーク間の追跡可能性を示しています（例: 脅威を OWASP Top 10 および ATLAS にマッピング、リスクを ISO/NIST カテゴリにマッピング）。
- ベンダーは、エージェント型システムとツール呼び出しアーキテクチャに適した安全なテスト基準、透明性のある推論、倫理的境界を重視しています。


# 4. 比較マトリックス: コンサルタント対自動ツール

| 基準 | AI レッド チーム コンサルタント | 自動化ツール |
| ----- | ----- | ----- |
| **強み**| 創造性、斬新性、創発的な動作の発見 | 規模、反復性、回帰テスト、スピード |
| **弱み** | コスト、可用性 | 適応性の限界、「網羅度の錯覚」のリスク |
| **単純なシステムへの適合性** | 高 | 高 |
| **ツール呼び出しシステムへの適合性** | 高 | 高（適切に計測されている場合） |
| **MCP システムへの適合性** | 高 | 中～高 |
| **マルチ エージェント システムへの適合性** | 高 | 低～中 |
| **悪用のリスク** | 期待を超える | テスト スイートを完全な網羅度として扱う |
| **必要な顧客専門知識** | 中 | 高（生の結果の解釈のため） |


# 5. ベンダー評価のための調査質問

意思決定者は、これらの質問を活用することで、マーケティング上の主張を超えたベンダーの能力を探ることができます。これは網羅的なリストではありませんが、ベンダーのサービスや製品が顧客のビジネス ニーズに適しているかどうかを判断するための、どのような会話をすればよいかを示すガイドラインとなります。

## 普遍的な質問

- 脱獄だけでなく、新たな発見の例を示してください。
- マルチ ターン テストの再現性をどのように確保していますか？
- テストのうち、当社の使用事例に合わせてカスタマイズされている割合はどのくらいですか？
- 発見事項をどのようにビジネス リスクにマッピングしていますか？
- 幻覚、漏洩、または安全でないコンプライアンスをどのように測定していますか？
- テストにおいて、非決定論的な出力をどのように考慮していますか？

## 単純な生成 AI システムに関する質問

- 危険な幻覚や誤情報をどのようにテストしていますか？
- システム プロンプトの開示や入力漏洩をどのようにテストしていますか？
- 敵対的な使用状況における RAG の堅牢性をどのように評価していますか？
- 業界における現実的な誤用シナリオをシミュレートできますか？
- 複数の言語間で動作の一貫性をテストしていますか？

## ツール呼び出しに関する質問

- 安全でないツール呼び出しをどのようにトリガーし、検出していますか？
- デバッグのためにシーケンスを確定的に再生できますか？

## MCP に関する質問

- ツール間の機能エスカレーションをどのように検出ていますか？
- 実際の MCP の悪用例とその機能チェーンを示してください。

## マルチ エージェントに関する質問

- 創発的な敵対的動作を検知できますか？
- エージェントの役割の完全性をどのように評価し、エージェント間での役割の逸脱や混乱をどのように防ぎますか？
- エージェントと割り当てられたツールまたは機能間の権限境界と権限分離をどのようにテストしていますか？

# 6. ベンダー評価におけるよくある落とし穴

ベンダー選定を成功させるには、以下のよくある誤りを避ける必要があります。

- **単純なシステムは安全だと想定する**: ツールやエージェントが不足している場合でも、単純なシステムであっても重大なリスクが存在します。
- **脱獄とシステム全体を対象としたレッド チーム演習を混同する**: 脱獄は、エージェント型システムおよびツールを使用するシステムがもたらすリスクのごく一部です。例えば、システムは脱獄に対しては堅牢であっても、ウォレット拒否（DoW）攻撃に対しては依然として脆弱である可能性があります。
- **洗練されたデモを重視する**: 単純で既知の攻撃のデモよりも、証拠（ログ、トレース、再現性）を要求します。
- **最新のアーキテクチャをチャットボットのように扱う**: MCP、ツール呼び出し、またはマルチ エージェント システムは、シングル ターン LLM の単なる拡張版であると考えるのは、システム全体の失敗です。
- **自動化が経験豊富な敵対者に取って代わると考える**: 自動化は拡張可能ですが、人間のコンサルタントは、斬新で複雑なコンテキスト固有の創造性を提供します。
- **創発的な動作を考慮しない指標を信頼する**: 指標は、エージェント間の汚染と目標エスカレーションを明確に定量化する必要があります。
- **検証せずに再現性を想定する**: 複雑なマルチ エージェントまたはツール使用の障害については、決定論的なリプレイ機能が必要です。
- **ツール呼び出しと MCP 出力が本質的に安全であると想定する**: 安全でないツールの実行、機能エスカレーション、ツールやエージェントを介した権限エスカレーション経路などのリスクを無視します。
- **特注の主張を過大評価する**: ベンダーは「私たちが構築します」を強みとして主張しますが、これは多くの場合、拡張可能なエンタープライズ対応の方法論の欠如を示しており、高価で実証されていない特注のテスト スイートにつながります。

# 7. ベンダー評価のチェックリスト

このチェックリストは、潜在的なベンダーを評価するために使用できます。

| 基準のカテゴリ | AI レッド チーム演習コンサルタントの要件 | 自動化ツールの要件 |
| ----- | ----- | ----- |
| **技術的能力** | MCP、ツール呼び出し、マルチ エージェント リスクに関する深い知識を実証済みです。 | 最新のアーキテクチャのイントロスペクションをサポートします。|
| **方法論と網羅性** | すべてのコンポーネントにわたる複雑かつ適応的な攻撃チェーンを網羅。 | 既存の脱獄ライブラリを超えるテストの自動化。|
| **敵対的な創造性** | 斬新でドメイン固有の敵対戦略を策定する能力。 | 攻撃生成における高い多様性と適応性。 |
| **脅威モデリング** | 脱獄にとどまらず、システム障害（例: ツールによるリソースの不正利用）にまで及びます。 | 自動テストへのカスタム脅威モデルのマッピングをサポートします。 |
| **評価の厳密さと指標** | 人間による検証済みのスコアリング。重大度は現実世界のリスクに結びついています。 | ツール呼び出しの堅牢性/MCP の悪用に関する明確で客観的な指標を提供します。 |
| **ツールとインフラストラクチャ** | 機密性の高いインタラクションのための安全なアクセス制御とログ記録。 | 環境内テストとシーケンスの確定的な再生をサポートします。|
| **データ ガバナンスとセキュリティ** | 機密性の高いログ/プロンプト/出力の取り扱いに関する明確なポリシー。 | オンプレミスまたはセルフホスティングのオプションがあり、MCP ツール アクセスデータを保護します。|
| **透明性と可能性** | 完全なメッセージとアクションのトレース、ツール呼び出しの出所を提供します。 | マルチ ターン/マルチ エージェント テストの各ステップの詳細なログを出力します。 |
| **カスタマイズと適応性** | カスタム エージェントのワークフローと特注ツールに適応可能。 | カスタム攻撃フローとポリシーの定義をサポートします。|
| **運用適合性/統合** | CI/CD または開発ワークフローへの統合のための明確な計画。 | API は軽減策の自動回帰テストをサポートします。|
| **既知の制限とバイアス** | 範囲と盲点（例: 創発的な動作）について透明性を保ちます。 | 「網羅性の錯覚」を過剰な主張をしたり依存したりしません。 |
| **コスト対価値** | 価格設定モデルは明確で、ROI はリスク軽減に重点を置いています。 | 継続的な再テストとスケーリングのための透明な価格設定。|
| **法的、倫理的、コンプライアンス態勢** | NIST AI RMF、OWASP、そして安全なテスト基準に準拠します。| 明確なデータ処理と証拠保全の手続き。|
| **エージェント型アクション空間** | 不正な状態変更（例: データベースへの書き込み）、混乱した代理問題(Confused Deputy) 攻撃、およびツールを介した権限昇格をテストする必要があります。 | 本番環境に影響を与えずに破壊的なツール呼び出しを安全にテストするために、「モック」または「ドライ ラン」実行モードをサポートする必要があります。 |
| **計画策定と推論のロジック** | 目標の乗っ取り、無限ループ、エラー処理の乱用（エージェントを安全でないフォールバック モードに強制する）を手動でテストする機能。| 無限ループの検出、リソース枯渇 (DoS) 制限、トークン予算の強制のための自動プローブ。|
| **間接インジェクション（トロイの木馬）** | エージェントの指示をサイレントに再配線するには、「汚染されたコンテキスト」攻撃 (RAG 内の悪意のある PDF や電子メールなど) をシミュレートする必要があります。| RAG パイプラインまたは文書検索システムのモックにペイロードを挿入して、検索防御をテストする機能。|


# 謝辞

## 貢献者

























