# 4. 付録と参考情報

## はじめに

この章では、OWASP AI Testing Guide の本文を補完するすべてのサポート資料を提供します。付録では、ガイドで提案されている方法論を補強する、構造化されたフレームワーク、脅威モデル、リスク ライフサイクル、およびドメイン固有のガイダンスを提供します。

これらのリソースは、主に以下の 3 つの目的に役立ちます。

1. 本書の前半で紹介した概念を**深化させます**。
2. モデル、マッピング、および方法論を通じて AI テストを**運用可能にします**。
3. 業界標準、セキュリティ分類、および学術文献に基づいてガイドを**構築します**。

本章の最後には、ガイド全体で使用されているすべての情報源を網羅した**参考情報**セクションがあります。

### 4.1 付録 A: SAIF (Secure AI Framework) 採用の根拠

付録 Aでは、信頼できる AI 開発とテストの基盤モデルとして SAIF (Secure AI Framework) を採用した根拠について説明します。

SAIF は以下の特長を備えています。

- データ、モデル、アプリケーション、インフラストラクチャ層を網羅する包括的な構造
- AI システムに合わせたセキュア・バイ・デザインの視点
- 最新のリスク分類法とガバナンス フレームワークとの整合性
- 脅威、リスク、アーキテクチャに関する付録との概念的な連続性

この付録では、AI が従来のソフトウェア テスト パラダイムを超えたフレームワークを必要とする理由を説明します。

### 4.2 付録 B: 分散化 (Distributed)、不変 (Immutable)、一時的 (Ephemeral)（DIE）による脅威の特定

この付録では、クラウド ネイティブおよび最新の AI 環境における脅威を特定するためのレンズとして、DIE モデル（分散化、不変、一時的）を紹介します。

AI システムには、多くの場合、次のような要素が含まれます。

- 分散コンピューティング クラスタ
- 不変のアーティファクト（コンテナ、モデル バイナリなど）、
- 一時的なジョブ（学習パイプライン、マイクロ サービスなど）

これらの特性により、固有の攻撃対象領域が生まれます。DIE フレームワークは、サプライチェーン インジェクション、改ざんされたアーティファクト、ワークフロー操作、クラウド環境の悪用といった脅威をテスターが認識するのに役立ちます。

### 4.3 付録 C: セキュアな AI システムのリスク ライフサイクル

付録 Cでは、AI システムの動的かつ進化する性質を反映した、AI 固有のリスク ライフサイクルについて説明します。

ライフサイクルには、以下の内容が含まれます。

- リスクの特定
- 発生可能性と影響の評価
- 軽減戦略の設計
- ドリフトや敵対者による操作の監視
- 残存リスクのレビューと管理策の更新

データ ドリフト、モデル ドリフト、フィードバック ループ リスクなど、AI システムに固有の現象には特に注意を払います。

#### 4.4 付録 D: AI アーキテクチャ コンポーネントへの脅威一覧

この付録では、AI アーキテクチャ コンポーネント全体にわたる脅威の構造化されたマッピングを提供します。これには、以下が含まれます。

- データ層
- モデル層
- アプリケーション/API 層
- インフラストラクチャ、およびデプロイメント環境

各コンポーネントについて、付録では以下の詳細を説明します。

- 主要な脅威ベクトル
- 一般的な脆弱性
- 層間の伝播効果

この一覧は、本ガイドの前半で定義したテスト手順の基礎となります。

### 4.5 付録 E: AI システムの脆弱性（CVE および CWE）に対する AI 脅威のマッピング

付録 Eでは、AI 固有の脅威を、以下の既存の脆弱性分類と関連付けています。

- CWE（共通脆弱性列挙）
- CVE（共通脆弱性識別子）
- 関連する MITRE 分類

このマッピングは、モデル抽出、プロンプト インジェクション、学習データ漏洩といった脅威が、従来のソフトウェア脆弱性クラスとどのように関連しているかを示しています。目標は、AI セキュリティ テストを既存のエンタープライズ脆弱性管理ワークフローに統合することです。

### 4.6 参考情報
最後のセクションでは、このガイド全体で引用されているすべての情報源（標準規格、学術研究、業界論文、オープン ソース プロジェクトなど）をまとめています。これらの参考情報は、OWASP AI Testing Guide で概説されているフレームワーク、方法論、推奨事項を裏付ける基礎資料を提供します。

-------------------------------------------------------------------

## 4.1 付録 A: AI 脅威モデリングのアーキテクチャ適用範囲として SAIF を選択した理由

AI 脅威モデリングのアーキテクチャ適用範囲として Google の SAIF を採用した理由は、システムをデータ、モデル、アプリケーション、インフラストラクチャの各層に明確に分解し、構造化されたテストとセキュリティ管理策の整合を可能にするためです。

OWASP AI セキュリティ マトリックスは、脅威に焦点を当て、潜在的な攻撃対象を中心に構成されていますが、SAIF は防御とセキュア設計に重点を置いています。両フレームワークは高度に補完的です。SAIF はセキュリティ保護の対象を定義するのに役立ち、OWASP はセキュリティ保護の対象を定義するのに役立ちます。どちらも強固な基盤として機能し、実際には、両方を整合させることで脅威の網羅性とアーキテクチャの追跡可能性が強化されます。

ここでは、OWASP AI セキュリティ マトリックスで定義されている AI アーキテクチャ コンポーネントと、Google の SAIF (Secure AI Framework) で定義されている AI アーキテクチャ コンポーネントを比較します。これにより、各フレームワークの共通の重点分野と固有の要素をマッピングすることで、脅威モデリングとセキュリティ テストの取り組みを整合させることができます。

<div align="center">
OWASP AI セキュリティ マトリックスと Google SAIF でのコンポーネント比較
	
<table>
<tr>
	<th width="20%">コンポーネント カテゴリ</th>	
	<th width="20%">OWASP AI セキュリティ マトリックス</th>	
	<th width="20%">Google SAIF アーキテクチャ</th>	
	<th width="40%">コメント</th>	
</tr>
<tr>
	<td>データ</td>
	<td>学習データ、入力データ、出力データ</td>
	<td>データ（学習、推論、変換、取り込みに渡ります	）</td>
	<td>どちらも学習と入力データの完全性を含みますが、SAIF はデータのライフサイクルをより包括的に扱います。</td>
</tr>
<tr>
	<td>モデル</td>
	<td>モデル アーキテクチャ、モデル パラメータ、モデル アーティファクト、モデル出力</td>
	<td>モデル（入力の処理、利用、出力の処理）</td>
	<td>OWASP はモデルをアーティファクトとアーキテクチャに分割し、SAIF は実行時とガードレールを強調します</td>
</tr>
<tr>
	<td>アプリケーション</td>
	<td>プロンプト インターフェース、API、プラグイン、出力チャネル</td>
	<td>アプリケーション、エージェント/プラグイン、ユーザー入出力</td>
	<td>強力な整合性: OWASP「プロンプト インターフェース」= SAIF「ユーザー入力」; プラグイン/コンポーネントも同じく整合</td>
</tr>
<tr>
	<td>インフラストラクチャ</td>
	<td>モデルのデプロイメント環境、CI/CD パイプライン、クラウド プラットフォーム/ホスティング</td>
	<td>インフラストラクチャ、モデル サービング、モデル ストレージ、モデル評価、学習インフラ</td>
	<td>OWASP と SAIFは、どちらもデプロイメント環境と実行時環境に重点を置いていますが、SAIF はよりきめ細かです。</td>
</tr>
<tr>
	<td>セキュリティ ガバナンス</td>
	<td>監視、ログ記録、アクセス制御</td>
	<td>ログ記録＆監査、アクセス制御、アイデンティティと認証</td>
	<td>どちらのフレームワークにも、テスト、追跡可能性、制御に不可欠なガバナンス コンポーネントが含まれています。</td>
</tr>
<tr>
	<td>外部依存関係</td>
	<td>サードパーティーのデータ フィード、事前学習済みモデル、API/LLM</td>
	<td>外部ソース、プラグイン統合</td>
	<td>SAIF は信頼境界を明示的に指定し、OWASP はサードパーティー モデルのリスクに対処します。</td>
</tr>

</table>
</div>

### 4.2 付録 B: 分散化 (Distributed)、不変 (Immutable)、一時的 (Ephemeral)（DIE）による脅威の特定

AI モデルは大規模に運用され、高度に動的なデータフローに依存し、しばしば不透明な「ブラックボックス」として機能するため、予期せぬ障害モードや攻撃対象領域が生じる可能性があります。この問題に対処するため、DIE トライアド（分散化、不変、一時的）は、補完的で回復力に重点を置いたフレームワークを提供します。Sounil Yu [20] によって最初に提唱された DIE モデルは、従来のデータ保護からシステムの生存性、適応性、そしてアーキテクチャの堅牢性へと焦点を移しています。モデルのドリフト、敵対的な入力、依存関係の連鎖が常に懸念される AI の文脈において、DIE 原則を適用することで、AI システムがセキュアであるだけでなく、設計上回復力を備え、中断や劣化に耐えられることを保証できます。

CIA（機密性、完全性、可用性）は、データとシステムを不正アクセスや中断から保護することに重点を置いていますが、DIE は、以下の点を重視する設計原則を通じて、攻撃対象の価値と寿命を低減することに重点を移しています。

- **分散化** – **システムは単一障害点に依存してはなりません**。ワークロード、データ、サービスは、回復力、スケーラビリティ、フォールト トレランスを確保するために、複数のノードに分散されます。
- **不変** – **コンポーネント、特にコードとデータは、デプロイ後に変更されてはなりません**。これにより、改ざんが制限され、ロールバックが簡素化され、監査可能性と予測可能性が確保されます。
- **一時的** – **システムは設計上、短命である必要があります**。コンテナ、関数、セッション、データはすぐに期限切れになるよう設計することで、攻撃の機会を減らし、侵害が発生した場合のリスクを最小限に抑えます。



