# 2. AI システムに対する脅威モデリング

## 脅威モデリングとは？

脅威モデリングとは、システムに対するセキュリティ上の脅威を特定、定量化し、対処するための構造化されたプロセスです。開発者、アーキテクト、セキュリティ専門家は、これにより、システムがどのように攻撃される可能性があるかを事前に評価し、開発ライフ サイクルの早い段階で適切な防御策を設計することができます。

AI システムにおいて、脅威モデリングは、新たに出現し高度化する脅威ベクトルを明らかにし、データ資産に対する潜在的な攻撃経路を明確化し、技術面とビジネス面の両方への影響を定量化します。これらのリスクは、プロンプト インジェクションからモデル抽出に至るまで、機械学習と生成 AI 技術の独特な特性から生じます。

## AI 脅威モデリングのコア目標

AI システムの脅威モデリングは、AI 固有の攻撃対象領域を特定し、影響度の高いリスク（敵対的攻撃や推論攻撃など）を優先順位付けし、標的を絞ったテストを導くことを目的としています。これにより、セキュア・バイ・デザイン（設計段階からセキュアなアーキテクチャ）が促進され、エンジニアリング、セキュリティ、コンプライアンスの各チーム間で共通のリスク言語が構築され、規制デューデリジェンスのための文書化された証拠が提供されます。脅威モデルを継続的に更新することで、組織はAIコンポーネントや脅威の進化に合わせて適応する、生きたリスク ロードマップを維持できます。

目標の定義に加えて、AI 脅威モデリングには以下のことが含まれます。

- **攻撃対象領域の分析**: AI/ML システムをコンポーネント（データソース、学習パイプライン、推論エンドポイント、モデル ストア、オーケストレーション レイヤー）に分解します。データフローをマッピングし、悪意のある入力や情報漏洩が発生する可能性のある信頼境界を特定します。
- **資産とアクターの特定**: 重要な資産（学習データセット、モデル パラメーター、推論 API）と、それらを操作するユーザーまたはプロセスをカタログ化します。権限レベルと潜在的な脅威アクター（外部攻撃者、不正な内部関係者、サードパーティ サービス）を特定します。
- **脅威ライブラリのマッピング**: 既存の脅威カタログを活用し、AI 固有の攻撃を包括的にカバーします。
- **リスク分析と優先順位付け**: 各脅威の発生可能性と影響度を、技術面（モデルの完全性、可用性）とビジネス面（収益損失、風評被害）の両方から推定します。脅威をランク付けし、リスクを最も低減できる箇所にテストと軽減策を集中させます。
- **軽減戦略の定義**: 優先順位付けされた脅威ごとに、リスクを許容レベルまで低減するために必要なアーキテクチャ管理策、ランタイム防御、または運用プロセスを指定します。

## AI 脅威モデリング フレームワークの選択方法

AI システムに対する脅威を体系的に特定・分析するために、いくつかの確立された方法論を応用することができます。それぞれが、ビジネス主導のリスク中心のアプローチから、プライバシー重視の評価や敵対的攻撃マッピングまで、独自の視点をもたらします。これらのフレームワークを慎重に適用することで、チームは AI 固有の脆弱性を発見し、軽減策を優先順位付けし、AI ライフサイクル全体にわたってセキュリティを統合することができます。

以下は、AI 脅威モデリングに用いられる主要な方法論の概観です。

- **PASTA<sup>[9]</sup> (Process for Attack Simulation and Threat Analysis)**: 技術分析とビジネスへの影響を整合させる、7 段階のリスク中心のフレームワーク。
- **STRIDE<sup>[10]</sup>**: Microsoft の STRIDE モデルで、脅威をなりすまし (spoofing)、改ざん (Tampering)、否認 (Repudiation)、情報漏洩 (Information disclosure)、サービス拒否 (Denial of service)、権限昇格 (Elevation of Privilege) に分類します。
- **MITRE ATLAS<sup>[11]</sup>**: 敵対的機械学習手法（回避、汚染、モデル抽出）とそれに対応する軽減策をマッピングします。
- **LINDDUN<sup>[12]</sup>**: データの機密性とコンプライアンスに対する脅威（メンバーシップ推論、データ漏洩など）をモデル化するための、プライバシー重視のフレームワーク。
- **MAESTRO<sup>[24]</sup>**: エージェント型 AI の脅威モデリング向けに特別に設計された、新しいモデル駆動型アプローチ。MAESTRO は、Multi-Agent Environment（マルチ エージェント環境）、Security（セキュリティ）、Threat（脅威）、Risk（リスク）、Outcome（結果）の頭文字をとったものです。

以下のような、組織の目標、システムの複雑さ、そしてステークホルダーのニーズに最も適した方法論を選択してください。

- **ビジネスとリスクの整合**: セキュリティ分析を具体的なビジネス影響（例：損失エクスポージャーの定量化）に結び付けることが主な目標である場合は、PASTA のようなリスク中心のフレームワークが理想的です。
- **スコープと複雑さ**: エンドツーエンド の AI パイプラインには、幅広い段階のプロセス（PASTA、MITRE ATLAS）を使用します。個々のコンポーネントには、より簡略化された分類法（STRIDE、OWASP LLM Top 10）が適しています。
- **対象者と成熟度**: 経営幹部やリスク管理担当者は、ビジネスに焦点を当てた高レベルのアウトプット（PASTA のビジネス目標ステージ、リスク登録簿）を好む傾向があります。エンジニアリング チームは、設計パターンやコードに直接マッピングできる、開発者にとって使いやすい分類法（AI-STRIDE または MITRE ATLAS マトリックス）を好む場合があります。
- **プライバシー対セキュリティ**: データの機密性とコンプライアンスが最優先事項である場合は、プライバシー中心の手法（LINDDUN）をコア セキュリティ アプローチと併せて導入してください。敵対的攻撃に対する堅牢性が最優先事項である場合は、選択したフレームワーク（MITRE ATLAS または カスタム AI-STRIDE 拡張）に敵対的テストケース設計が含まれているか、簡単に統合できることを確認してください。
- **エージェント型 AI の脅威モデリング**: AI エージェントがユーザー、ツール、他のエージェント、またはその環境と対話するシステムにおけるリスクをモデル化する必要がある場合は、MAESTRO（注 (a)）を使用してください。これは、現実世界の AI の障害やセキュリティ問題の多くが発生するコンテキストです。
- **LLM を活用した脅威モデリング**: 大規模言語モデル（LLM）は、従来は手動で時間のかかる複数のステップを自動化することで、脅威モデリング プロセスを効率化できます。参考情報 [25] のトレーニングで扱われている LLM 拡張型脅威モデリングでは、大規模言語モデルを用いて脅威モデリング プロセスの各段階を加速・強化し、システム記述（テキスト ベースの文書、アーキテクチャ図、あるいはコードなど）から直接、脅威や緩和策、そして管理策に関する推奨事項を自動生成します。
- **ツールとプロセスの適合性**: 既存の SDLC、脅威モデリング ツール、レポート ダッシュボードと互換性のある方法論を選択してください。PASTA の各段階は、リスク管理プラットフォームで適切に機能し、LLM 脅威モデリング プロンプト テンプレート（注(b)）を用いて LLM を活用できます。STRIDE は、ThreatDragon のような手動の脅威モデリング ツールと、STRIDEGPT のような LLM を活用した脅威モデリング ツールの両方に簡単にマッピングできます。

----------------------------------
<div style="font-size: small">

- 注 (a): MAESTRO は、STRIDE、PASTA、その他の従来のフレームワークに代わるものではなく、AI 固有の脅威クラス、マルチ エージェント コンテキスト、およびライフサイクル全体のセキュリティの考慮事項を追加することで、それらを補完します。
- 注 (b): 特別に設計されたプロンプト テンプレートを使用することで、LLM を用いた脅威モデリング プロセスを強化できます。STRIDE および PASTA LLM 脅威モデリング プロンプト テンプレートの例は、参考文献 [26] でいくつか公開されています。これらのテンプレートは、大規模言語モデル（LLM）が脅威モデリング タスクを一貫性と精度をもって実行できるように、再利用可能な構造化されたプロンプトを提供します。
</div>
