# 2. AI システムに対する脅威モデリング

## 脅威モデリングとは？

脅威モデリングとは、システムに対するセキュリティ上の脅威を特定、定量化し、対処するための構造化されたプロセスです。開発者、アーキテクト、セキュリティ専門家は、これにより、システムがどのように攻撃される可能性があるかを事前に評価し、開発ライフ サイクルの早い段階で適切な防御策を設計することができます。

AI システムにおいて、脅威モデリングは、新たに出現し高度化する脅威ベクトルを明らかにし、データ資産に対する潜在的な攻撃経路を明確化し、技術面とビジネス面の両方への影響を定量化します。これらのリスクは、プロンプト インジェクションからモデル抽出に至るまで、機械学習と生成 AI 技術の独特な特性から生じます。

## AI 脅威モデリングのコア目標

AI システムの脅威モデリングは、AI 固有の攻撃対象領域を特定し、影響度の高いリスク（敵対的攻撃や推論攻撃など）を優先順位付けし、標的を絞ったテストを導くことを目的としています。これにより、セキュア・バイ・デザイン（設計段階からセキュアなアーキテクチャ）が促進され、エンジニアリング、セキュリティ、コンプライアンスの各チーム間で共通のリスク言語が構築され、規制デュー デリジェンスのための文書化された証拠が提供されます。脅威モデルを継続的に更新することで、組織はAIコンポーネントや脅威の進化に合わせて適応する、生きたリスク ロードマップを維持できます。

目標の定義に加えて、AI 脅威モデリングには以下のことが含まれます。

- **攻撃対象領域の分析**: AI/ML システムをコンポーネント（データソース、学習パイプライン、推論エンドポイント、モデル ストア、オーケストレーション層）に分解します。データフローをマッピングし、悪意のある入力や情報漏洩が発生する可能性のある信頼境界を特定します。
- **資産とアクターの特定**: 重要な資産（学習データセット、モデル パラメーター、推論 API）と、それらを操作するユーザーまたはプロセスをカタログ化します。権限レベルと潜在的な脅威アクター（外部攻撃者、不正な内部関係者、サードパーティ サービス）を特定します。
- **脅威ライブラリのマッピング**: 既存の脅威カタログを活用し、AI 固有の攻撃を包括的にカバーします。
- **リスク分析と優先順位付け**: 各脅威の発生可能性と影響度を、技術面（モデルの完全性、可用性）とビジネス面（収益損失、風評被害）の両方から推定します。脅威をランク付けし、リスクを最も低減できる箇所にテストと軽減策を集中させます。
- **軽減戦略の定義**: 優先順位付けされた脅威ごとに、リスクを許容レベルまで低減するために必要なアーキテクチャ管理策、ランタイム防御、または運用プロセスを指定します。

## AI 脅威モデリング フレームワークの選択方法

AI システムに対する脅威を体系的に特定・分析するために、いくつかの確立された方法論を応用することができます。それぞれが、ビジネス主導のリスク中心のアプローチから、プライバシー重視の評価や敵対的攻撃マッピングまで、独自の視点をもたらします。これらのフレームワークを慎重に適用することで、チームは AI 固有の脆弱性を発見し、軽減策を優先順位付けし、AI ライフサイクル全体にわたってセキュリティを統合することができます。

以下は、AI 脅威モデリングに用いられる主要な方法論の概観です。

- **PASTA<sup>[9]</sup> (Process for Attack Simulation and Threat Analysis)**: 技術分析とビジネスへの影響を整合させる、7 段階のリスク中心のフレームワーク。
- **STRIDE<sup>[10]</sup>**: Microsoft の STRIDE モデルで、脅威をなりすまし (spoofing)、改ざん (Tampering)、否認 (Repudiation)、情報漏洩 (Information disclosure)、サービス拒否 (Denial of service)、権限昇格 (Elevation of Privilege) に分類します。
- **MITRE ATLAS<sup>[11]</sup>**: 敵対的機械学習手法（回避、汚染、モデル抽出）とそれに対応する軽減策をマッピングします。
- **LINDDUN<sup>[12]</sup>**: データの機密性とコンプライアンスに対する脅威（メンバーシップ推論、データ漏洩など）をモデル化するための、プライバシー重視のフレームワーク。
- **MAESTRO<sup>[24]</sup>**: エージェント型 AI の脅威モデリング向けに特別に設計された、新しいモデル駆動型アプローチ。MAESTRO は、Multi-Agent Environment（マルチ エージェント環境）、Security（セキュリティ）、Threat（脅威）、Risk（リスク）、Outcome（結果）の頭文字をとったものです。

以下のような、組織の目標、システムの複雑さ、そしてステークホルダーのニーズに最も適した方法論を選択してください。

- **ビジネスとリスクの整合**: セキュリティ分析を具体的なビジネス影響（例：損失エクスポージャーの定量化）に結び付けることが主な目標である場合は、PASTA のようなリスク中心のフレームワークが理想的です。
- **スコープと複雑さ**: エンドツーエンド の AI パイプラインには、幅広い段階のプロセス（PASTA、MITRE ATLAS）を使用します。個々のコンポーネントには、より簡略化された分類法（STRIDE、OWASP LLM Top 10）が適しています。
- **対象者と成熟度**: 経営幹部やリスク管理担当者は、ビジネスに焦点を当てた高レベルのアウトプット（PASTA のビジネス目標ステージ、リスク登録簿）を好む傾向があります。エンジニアリング チームは、設計パターンやコードに直接マッピングできる、開発者にとって使いやすい分類法（AI-STRIDE または MITRE ATLAS マトリックス）を好む場合があります。
- **プライバシー対セキュリティ**: データの機密性とコンプライアンスが最優先事項である場合は、プライバシー中心の手法（LINDDUN）をコア セキュリティ アプローチと併せて導入してください。敵対的攻撃に対する堅牢性が最優先事項である場合は、選択したフレームワーク（MITRE ATLAS または カスタム AI-STRIDE 拡張）に敵対的テストケース設計が含まれているか、簡単に統合できることを確認してください。
- **エージェント型 AI の脅威モデリング**: AI エージェントがユーザー、ツール、他のエージェント、またはその環境と対話するシステムにおけるリスクをモデル化する必要がある場合は、MAESTRO（注 (a)）を使用してください。これは、現実世界の AI の障害やセキュリティ問題の多くが発生するコンテキストです。
- **LLM を活用した脅威モデリング**: 大規模言語モデル（LLM）は、従来は手動で時間のかかる複数のステップを自動化することで、脅威モデリング プロセスを効率化できます。参考情報 [25] のトレーニングで扱われている LLM 拡張型脅威モデリングでは、大規模言語モデルを用いて脅威モデリング プロセスの各段階を加速・強化し、システム記述（テキスト ベースの文書、アーキテクチャ図、あるいはコードなど）から直接、脅威や緩和策、そして管理策に関する推奨事項を自動生成します。
- **ツールとプロセスの適合性**: 既存の SDLC、脅威モデリング ツール、レポート ダッシュボードと互換性のある方法論を選択してください。PASTA の各段階は、リスク管理プラットフォームで適切に機能し、LLM 脅威モデリング プロンプト テンプレート（注(b)）を用いて LLM を活用できます。STRIDE は、ThreatDragon のような手動の脅威モデリング ツールと、STRIDEGPT のような LLM を活用した脅威モデリング ツールの両方に簡単にマッピングできます。

----------------------------------
<div style="font-size: small">

- 注 (a): MAESTRO は、STRIDE、PASTA、その他の従来のフレームワークに代わるものではなく、AI 固有の脅威クラス、マルチ エージェント コンテキスト、およびライフサイクル全体のセキュリティの考慮事項を追加することで、それらを補完します。
- 注 (b): 特別に設計されたプロンプト テンプレートを使用することで、LLM を用いた脅威モデリング プロセスを強化できます。STRIDE および PASTA LLM 脅威モデリング プロンプト テンプレートの例は、参考文献 [26] でいくつか公開されています。これらのテンプレートは、大規模言語モデル（LLM）が脅威モデリング タスクを一貫性と精度をもって実行できるように、再利用可能な構造化されたプロンプトを提供します。
</div>

## AI システムのアーキテクチャ

脅威を包括的な AI アーキテクチャにマッピングすることが重要です。(*) 脅威はシステム設計に依存するため、AI システムの各部分（データ取り込み、学習パイプライン、モデル API、監視システム）にはそれぞれ異なる脆弱性があります。アーキテクチャを完全に可視化できなければ、重要な攻撃対象領域を見逃してしまう可能性があります。脅威を特定のコンポーネントにマッピングすることで、脅威が実際に発生する可能性のある場所を特定し、システムをブラック ボックスとして扱うのではなく、リスクの優先順位付けを行うことができます。脅威をアーキテクチャ全体にマッピングすることで、境界だけでなく、各重要な境界（データ、モデル、API、インフラストラクチャ）に階層化されたセキュリティ管理策を設計できます。脅威のマッピングは、構造化された脅威モデリング（AI 向けの STRIDE、PASTA、LINDDUN など）を体系的にサポートし、具体的で実用的な対策を容易に設計できるようになります。脅威モデリングはスコープとコンテキストに大きく依存するため、最も一般的なAI脅威を反映し、今日のほとんどの AI アプリケーションの基盤となる技術的およびビジネス的な使用事例と一致するアーキテクチャ範囲を選択することが重要です。

PASTA のステージ II では、Secure AI Framework（SAIF）<sup>[12]</sup>と整合させてアーキテクチャの範囲を定義し、AI システムのコア セキュリティ関連コンポーネントの構造化されたビューを確立します。SAIF は、大規模な AI システムのセキュリティを確保するための公開モデルとして機能し、AI システムのセキュリティをより広範なリスク管理および運用回復力の目標に結び付ける、実用的で適応性に優れたビジネスに合わせたフレームワークを提供します。特に、SAIF Risk Map<sup>[13]</sup> は、AI セキュリティをナビゲートするための視覚的なガイドとして機能し、包括的なセキュリティ フレームワークとしての SAIF を理解する上で中心的な役割を果たします。このマップは、プロンプト インジェクション、データ汚染、不正なアクションなど、開発者には馴染みのない多くのリスクを強調しています。AI 開発プロセスをマッピングすることで、SAIF マップはこれらのリスクが発生する場所を特定し、重要なことに、対応するセキュリティ管理策を適用できる場所を特定するのに役立ちます。図 1 に、SAIF コンポーネントの図を示します。

<div align="center">

![](./assets/AISystemArchitecture.png)

図 1: SAIF アーキテクチャの層とコンポーネント
</div>

SAIF マップ図は、AI セキュリティをアプリケーション、モデル、インフラストラクチャ、データの 4 つの主要領域に分類し、AI 開発ライフサイクル全体にわたる AI 保護の範囲を網羅しています。上半分は、モデルのデプロイメントとユーザー インタラクションまでのパスを示し、AI を活用したアプリケーションを構築するモデル利用者に最も関連性の高いリスクと管理策に焦点を当てています。SAIF マップ図の下半分は、モデルの開発プロセスを示し、モデル作成者、つまり自組織または他組織向けにモデルを学習または微調整する担当者に焦点を当てています。AI の使用方法によっては、より関連性の高いリスクが異なる場合があります。

SAIF Risk Map は、AI 開発ライフサイクルにおいて、多くの場合、人、プロセス、またはツールの脆弱性によってリスクが導入される場所、リスクが露出する場所（つまり、セキュリティ チームが観察またはテストできる場所）、そして適切な管理策の実装によって最終的にリスクを軽減できる場所を示しています。これらのリスク パスの一部は、主にモデル利用層（アプリケーションとモデル）と関連する AI コンポーネントに現れ、その他はモデル作成層（インフラストラクチャとデータ）に現れ、多くは両方にまたがるため、AI システムのライフサイクル全体にわたる包括的なセキュリティ網羅性の必要性が強調されます。

Google の Secure AI Framework（SAIF）を採用することで、すべてのサブ コンポーネント（RAG や記憶モジュールなど）を分解するのではなく、データ、学習、推論、デプロイメントという最上位ドメインに焦点を当てています。SAIF の構造との整合により、モデルの明確性が維持され、不要な複雑さを回避できます。


## AI システムのアーキテクチャの脅威モデリング

脅威モデリング手法の選択にあたっては、技術分析とビジネスへの影響を整合させるリスク中心のフレームワークとして、PASTA、MITRE ATLAS（敵対的テスト ケース設計を含む、または容易に統合可能なフレームワーク）、そして開発者にとって分かりやすい脅威分類のための STRIDE と STRIDE AI など、主要なアプローチをいくつか紹介します。どの手法を選択しても、望まれる本質的な成果は同じです。それは、アプリケーション、データ、モデル、インフラストラクチャといったコア コンポーネントを網羅し、SAIF Risk Map で定義された参照 AI アーキテクチャに脅威を体系的にマッピングすることです。

目標は、STRIDE の脅威カテゴリと AI 固有の脅威の両方を活用した包括的な脅威分析を実施することです。特定された脅威は、脅威駆動型および攻撃駆動型のテストを設計するための基盤となり、管理策ギャップ、弱点、脆弱性を明らかにするために使用されます。これらの（技術的およびビジネス的）脆弱性の発生可能性と影響は、それに応じて評価および軽減する必要があるリスクの次元を形成します。

PASTA のようなリスク ベースの手法を採用する場合、そのプロセスはビジネス目標の定義から始まります。つまり、重要な機能（パーソナライズされた推奨、予測分析、自律的な意思決定など）を提供する AI 活用サービスを保護しながら、顧客の信頼の喪失、規制上の罰則、モデルの侵害による競争上の脅威といったリスクを軽減することです。

PASTA のステージ 2 では、SAIF Risk Map を用いて、ユーザー、アプリケーション、モデル、データ、インフラストラクチャを網羅する包括的な技術的範囲を確立します。PASTA のステージ 3 では、アーキテクチャを 4 つの主要レイヤーに分解し、高レベルのデータフローをマッピングします。PASTA のステージ 4 では、AI 固有の脅威に対する詳細な脅威分析を実施します。PASTA のステージ 5 と 6 では、標的を絞ったテストと現実的な攻撃シナリオのシミュレーションを通じて、脆弱性を特定することに重点を置きます。最後に、PASTA のステージ 7 では、軽減されていないリスクの重大度を評価し、業界のベスト プラクティスに基づいて軽減戦略の概要を策定します。

一方、STRIDE を主要な脅威モデリング手法として直接採用する場合は、プロセスが異なります。STRIDE は、PASTA のような完全なエンド ツー エンドのリスク中心の脅威モデリング手法ではなく、脅威分類フレームワークとして機能するためです。このアプローチでは、6 つの STRIDE 脅威カテゴリを SAIF アーキテクチャ コンポーネント（アプリケーション、モデル、データ、インフラストラクチャ）全体に体系的に適用することで、包括的な脅威カバレッジを確保できます。ただし、STRIDE のみを使用する場合は、リスク スコアリングを組み込み、現実的な攻撃シナリオをシミュレートし、脅威をビジネスおよび運用コンテキストに合わせるための追加手順が必要です。これらの機能は、PASTA の手法に本質的に統合されています。

PASTA の 7 段階プロセスでは、MITRE ATLAS の AI 固有の敵対的戦術データベース（回避、汚染、モデル抽出、推論攻撃など）を脅威マッピングに組み込むことで、脅威分析フェーズを強化します。この統合により、リスク中心モデルがビジネスの優先事項と技術的範囲と一致すると同時に、最も重要な攻撃ベクトルに対する一連の攻撃的 AI テストに直接情報を提供します。 AI 固有の敵対的戦術（例えば、回避、汚染、モデル抽出など）は、レッド チーム演習のような専門的な AI セキュリティ評価の主要な対象です。この重点は、OWASP AI Red Teaming Framework<sup>[14]</sup> に正式に規定されており、AI システムに対するこれらの攻撃ベクトルをシミュレートおよび評価する方法が定義されています。

効果的な脅威モデリングは、保護すべき重要な資産を中心に分析の範囲を定めることから始まります。そのためには、まずシステムのアーキテクチャを、必須のコンポーネント、サービス、データ ストア、インターフェース、およびサポート インフラストラクチャに分解します。次に、エンド ツー エンドで情報を追跡し、入口と出口を強調し、信頼境界を確立するデータフロー図を描くことで、これらの構成要素がどのように相互作用するかをマッピングします。データが保存、処理、送信される場所を視覚化することで、リスクにさらされている資産を正確に特定し、各コンポーネントと境界に対する潜在的な脅威と脆弱性を体系的に特定できます。この構造化されたアプローチにより、脅威モデルは焦点が絞られ、包括的であり、組織のセキュリティの優先事項と一致したものになります。

これらのスコープ設定と分解、重要な資産の特定、システムのコア コンポーネントへの分割、そしてデータフロー図を用いたエンド ツー エンドのインタラクションと信頼境界のマッピングといった活動は、STRIDE から PASTA に至るまで、多くの脅威モデリング手法に共通する基本的なステップであり、リスクの特定と優先順位付けに対する一貫性のある徹底的なアプローチを保証します。

SAIF に準拠した層（アプリケーション、データ、モデル、インフラストラクチャ）に重点を置くことで、脅威分析を意図的に高アーキテクチャ レベルに維持しています。これにより、システムのすべてのサブ コンポーネントを詳細に調査することなく、AI 固有のリスクを幅広くカバーできます。

この AI 脅威モデルでは、AI 固有の脅威を含む脅威をアプリケーション、データ、モデル、インフラストラクチャの各レイヤーにマッピングし、包括的な網羅性を確保しています。脅威の軽減策は、テスト可能な要件として定義され、検証活動は本ガイドに文書化されています。目標は、特定された脅威<sup>（注）</sup>に対する AI システムのセキュリティ態勢を評価するための包括的なテスト セットを提供することです。

注: OWASP AI Testing Guide は、デプロイメント後のセキュリティ評価を対象としており、MLOps ライフサイクル全体を網羅するものではないことにご注意ください。データ準備、モデルの学習、CI/CD パイプラインの早い段階で敵対的堅牢性テストを組み込むためのガイダンスを探しているチームには、参考文献 [16] "Securing AI/ML Systems in the Age of Information Warfare" のホワイト ペーパーをお勧めします。このホワイト ペーパーでは、AI/ML 開発プロセスにおける敵対的テスト手法について深く掘り下げた解説が提供されています。また、参考文献 [17] の John Sotiroupulos 氏の著書も確認してください。

## アーキテクチャの分解

脅威モデリングにおけるアーキテクチャ分解とは、システムを主要コンポーネント、データフロー、資産、信頼境界に分解するプロセスです。脅威が発生する可能性のある場所を特定し、体系的な脅威列挙（STRIDE など）をサポートし、攻撃対象領域を浮き彫りにして、潜在的な侵入ポイントと露出領域をすべて特定するのに役立ちます。

PASTA のステージ III に続いて、AI アーキテクチャを分解し、SAIF で定義された 4 つの層とコンポーネント グループ（データ、モデル、インフラストラクチャ、アプリケーション）に整理することで、構造化された包括的な脅威分析を可能にします。

SAIF (Secure AI Framework) モデルは、AI システムの高レベルなアーキテクチャ ビューを提供し、AI ライフサイクルのセキュリティ確保に不可欠なデータ、モデル、アプリケーション、インフラストラクチャなどの幅広いコンポーネント カテゴリを捉えるように設計されています。この抽象化は、AI セキュリティの共通ベースラインを確立する上で有用ですが、あらゆる特定の実装パターンの詳細な分解を提供することを意図したものではありません。

AI 脅威モデリングにおいて推奨されるアプローチは、Google の SAIF や OWASP AI Security Matrix といったフレームワークが提供するような、データ、モデル、アプリケーション、インフラの各層を包括的にカバーする高レベルのアーキテクチャ ビューから始まります。そこから、AI システムの具体的な導入環境（関連するテクノロジー、データフロー、統合ポイントなど）を反映する詳細レベルまでモデルを洗練させる必要があります。

このより深いレベルのモデリングは、特定の AI 使用事例に結びついた実際の攻撃対象領域を特定するために不可欠です。例えば、従業員の経費精算を自動化するロボティック・プロセス・オートメーション（RPA） ワークフローでは、[21] で説明されているように、脅威モデリングによってサードパーティー統合、データ処理、ビジネス ロジックにおけるリスクを把握する必要があります。マルチ エージェント システム（MAS）や検索拡張生成（RAG）<sup>（注）</sup>パイプラインなどのより複雑なアーキテクチャでは、脅威モデリングは SAIF 単独では提供できない範囲を拡張し、[22] で説明されているように、非常に具体的なレベルで脅威、脆弱性、および管理策を網羅する必要があります。

SAIF は、スコープ設定には役立ちますが、これらのハイブリッド化され動的にオーケストレーションされたコンポーネントを完全に分析するために必要な粒度を提供できない可能性があります。従って、脅威の状況を評価し、実際の AI デプロイメントにおける管理策の有効性をテストするには、より深い分解が必要です。

----------------------------------
<div style="font-size: small">

- 注: RAG（Retrieval-Augmented Generation）は、SAIF アーキテクチャでは明示的に定義されていませんが、その複合構造により、複数の SAIF コンポーネントにマッピングされます。RAG は、データ（汚染の影響を受けやすい外部ソース）、モデル（プロンプト操作の影響を受けやすい）、アプリケーション層（取得と生成を調整し、連鎖リスクをもたらす）、インフラストラクチャ（セキュアな構成を必要とするベクトル DB と LLM サービスをサポート）で構成されます。

</div>

## アプリケーション層

アプリケーション層は、アプリケーションと、それに関連するエージェントやプラグインを包含します。入出力に関してはユーザーと、処理と応答に関しては AI モデルとインターフェースします。エージェントとプラグインは機能を拡張しますが、管理が必要な追加の推移的リスクも生じます。

「アプリケーション」とは、AI モデルを活用して機能を提供する製品、サービス、または機能を指します。アプリケーションは、カスタマー サービス チャットボットのようにユーザー向けのものもあれば、内部システムがモデルと対話して上流プロセスをサポートするサービス指向のものもあります。

「エージェント/プラグイン」とは、AI アプリケーションまたはモデルによって特定のタスクを実行するために呼び出されるサービス、アプリケーション、または補足モデルを指します。これは「ツールの利用」と呼ばれることがよくあります。エージェントまたはプラグインは、外部データにアクセスしたり、他のモデルへのリクエストを開始したりできるため、呼び出しごとに追加の推移的リスクが生じ、AI 開発プロセスに固有の既存のリスクがさらに悪化する可能性があります。

アプリケーション層は、以下のサブ コンポーネントに分解できます。

- **ユーザー (SAIF #1)**: リクエストを発行しレスポンスを受信する人物またはシステムです。
- **ユーザー入力 (SAIF #2)**: ユーザーが送信する入力 (クエリ、コマンド) です。
- **ユーザー出力 (SAIF #3)**: アプリケーションからユーザーに返される、ユーザー アクションへの応答などの出力です。
- **アプリケーション (SAIF #4)**: ユーザー I/Oを受け取り、AI モデルを呼び出すか外部サービスを呼び出すかを決定し、レスポンスの書式を整えるコア ロジックです。
- **エージェント/プラグイン (SAIF #5)**<sup>（注）</sup>: アプリケーションやモデルと対話して特定の機能を提供するプロセスです。検索ツールや、機能を拡張する一方で追加の信頼境界を導入するサードパーティー API などです。
- **外部ソース (SAIF #6)**: これらのエージェントが依存するデータベース、サービス、または API です。それぞれが外部エンティティと潜在的なリスク ポイントを表します。

----------------------------------
<div style="font-size: small">

- 注: このガイドは、テスト目的で SAIF 定義の資産に対する脅威のマッピングに範囲を限定しています。 AI 脅威モデリングの範囲として SAIF を選択した理由は、付録 A に記載されています。
- 注: SAIF #5（エージェント/プラグイン）から SAIF #6（外部ソース）への点線は、プラグインが実行時に外部サービスから信頼できないデータを動的に取得または照会することを反映しています。

</div>

## モデル層

モデル層は、AI または ML のコア コンポーネント自体、つまり入力を出力に変換するロジック、パラメータ、実行時をカバーし、アプリケーション（およびエージェント／プラグイン）と基盤となるインフラストラクチャまたはデータの間に位置します。この層は、AI の「ブラック ボックス」を体現しているため、汚染、漏洩、または誤用を防ぐために、入力、出力、および推論操作を慎重に処理する必要があります。

モデル層は、以下のサブ コンポーネントに分解できます。

- **入力の処理 (SAIF #7)**<sup>（注）</sup>: その目的は、モデルに到達する前にすべてのデータ、プロンプト、または特徴ベクトルを検証および無害化し、インジェクション攻撃、データ汚染、または意図しない動作につながる可能性のある不正な入力を防ぐことです。入力の処理は、3 つの主要機能で構成されます。不正なデータをクリーンアップまたは拒否する入力検証機能、許可された呼び出し元のみを許可する認証と認可機能、そしてサービス拒否攻撃や総当り攻撃を防ぐレート リミッターです。
- **出力の処理 (SAIF #8)**<sup>（注）</sup>: その目的は、モデル出力をフィルタリング、編集、または後処理し、機密性の高い学習データの漏洩、プライバシーの侵害、または有害なコンテンツの生成を防ぐことです。これには、有害なコンテンツや許可されていないコンテンツを検出してブロックする出力フィルター、機密情報や個人情報を削除する無害化と編集機能、そして出力が配信前に書式の整形とビジネス ルールに準拠していることを確認する応答検証機能が含まれます。
- **モデルの利用 (SAIF #9)**: 制御された監査可能な環境において、承認された入力に対してモデルを実行し、実行時に推論ロジックが改ざんまたは破壊されないようにします。これには、重みを読み込み出力を計算する推論エンジン、ガードレールを適用するポリシー適用（トークン制限、安全なデコードなど）、および追跡可能性のために入力、モデルバージョン、および出力を記録する監査ロガーが含まれます。

----------------------------------
<div style="font-size: small">

- 注: SAIF #5（エージェント/プラグイン）から SAIF #7 (入力の処理) および SAIF #8（出力の処理）への 2 本の点線は、プラグインがプロンプトを動的に変更したり、モデル出力を後処理したりする方法を示しています。

</div>

## インフラストラクチャ層

インフラストラクチャ層は、他のすべての AI システムのコンポーネントをホストおよび接続するための基盤となるコンピューティング、ネットワーク、ストレージ、オーケストレーション サービスを提供します。リソースのプロビジョニング、分離、安全な管理を保証し、データ処理、モデル学習、推論、監視まで、あらゆるプロセスをサポートします。

インフラストラクチャ層は、以下のサブ コンポーネントに分解できます<sup>（注）</sup>。

- **モデル ストレージ インフラストラクチャ (SAIF #10)**: このコンポーネントは、重みファイル、構成データ、バージョン管理されたメタデータなどのモデル アーティファクトの保存と取得を保護し、それらの機密性、完全性、可用性を維持します。アーティファクト リポジトリはバージョン管理を維持し、保存時に暗号化を適用します。一方、完全性検証ツールは、アップロードとダウンロードのたびに暗号化ハッシュ（SHA-256 など）を計算および検証し、改ざんを検出します。鍵管理サービスは、最小権限ポリシーに基づいて暗号化鍵を発行および変更し、保存されたモデルの不正な復号を防止します。
- **モデル サービング インフラストラクチャ (SAIF #11)**: このコンポーネントは、モデルが推論リクエストを実行する実行時環境を提供します。モデル実行プロセスを他のワークロードから分離し、リソース クォータとレート制限を適用し、適切にフォーマットされた入力のみがモデルに到達するようにします。正常性監視機構は障害やパフォーマンスの低下を検出し、自動スケーリングまたは負荷分散は要求の変化下でも中断のない可用性を確保します。
- **モデルの評価 (SAIF #12)**: このコンポーネントは、デプロイ前後のモデルのパフォーマンス、公平性、堅牢性を測定します。検証スイートは、敵対的入力やエッジ ケース入力を含む予約済みのテスト セットに対してモデルを実行し、精度、バイアス、エラー率に関する指標を収集します。ドリフト検出ツールは、新しい出力を過去のベースラインと比較し、大きな逸脱をフラグ付けします。また、レポート ダッシュボードは、修正措置のための回帰やポリシー違反を明らかにします。
- **モデルの学習と調整 (SAIF #13)**: このコンポーネントは、キュレーションされたデータセット上でモデルを作成および改良するエンド ツー エンドのプロセスをオーケストレーションします。学習パイプラインは、制御された条件下でデータの前処理、特徴量エンジニアリング、反復的なモデル フィッティングを管理します。ハイパー パラメータ管理ツールは各実験の設定と結果を記録し、データ無害化ルーチンは機密情報を匿名化またはフィルタリングすることで、学習中のプライバシーを保護します。
- **モデル フレームワークとコード (SAIF #14)**: このコンポーネントには、モデル アーキテクチャと学習ルーチンを定義するライブラリ、フレームワーク、カスタム コードが含まれます。静的解析および依存関係スキャン ツールは、サードパーティー製パッケージの既知の脆弱性を検出します。設計段階からセキュリティを重視したコード レビューにより、安全でない動的実行やハード コードされた認証情報の回避といったベスト プラクティスが徹底され、強化された実行時環境により、モデル サービング コードや学習コードの攻撃対象領域が制限されます。
- **データ ストレージ インフラストラクチャ (SAIF #15)**: 「データ」は SAIF 独自のドメインにまたがっていますが、特徴量ストアや埋め込みインデックスといったモデル固有のストレージ システムには、専用のセキュリティ管理策が必要です。これらのストアは、アクセス ポリシーを適用し、データ スキーマと書式を検証し、すべての読み取り/書き込み操作をログに記録して追跡可能性を確保します。保存時および転送中の暗号化により、機密性の高い入力データと中間アーティファクトを保護し、定期的な完全性チェックにより不正な変更が行われないようにします。

## データ層

データ層は、モデルが利用する生データと処理済みデータを提供することで、あらゆる AI システムの基盤となります。データ層は、初期の収集と取り込みから、変換、保存、そして学習や推論のためのプロビジョニングに至るまで、データのライフサイクル全体を網羅し、データの正確性と信頼性を維持し、プライバシーとセキュリティ ポリシーへの準拠を保証します。この層の堅牢な管理策により、データの汚染、漏洩、不正アクセスから保護され、信頼性が高く責任ある AI 成果の基盤を形成します。

データ層は、以下のサブ コンポーネントに分解できます。

- **学習データ (SAIF #16）**: 学習データは、モデルにパターン認識と予測方法を学習させるために使用される、キュレーションされたラベル付きサンプル データで構成されます。セキュアな AI パイプラインでは、組織は学習データセットの完全性を保証するために、厳格な出所とバージョン管理を確立します。すべてのレコードの出所、変更履歴、アクセス イベントはログに記録され、監査可能な状態にします。学習リポジトリに対して保存時の暗号化とロール ベースの権限設定を適用することで、システムは不正な改ざんを防止します。学習コーパスへの不正な変更は、モデルの学習プロセスを破壊し、敵対的な操作につながる可能性があります。
- **データのフィルタリングと処理 (SAIF #17）**：生の入力データをモデル パイプラインに取り込む前に、データは厳格なフィルタリングと処理のステップを経ます。これには、スキーマ検証、破損または悪意のあるエントリを除去するための異常検出、匿名化や仮名化などのプライバシー保護のための変換が含まれます。セキュアな処理フレームワークは、適用されたすべての変換を記録する再現可能なパイプラインを使用して、これらのタスクを隔離された環境で実行します。各段階できめ細かなアクセス制御と変更追跡を組み込むことで、システムは検証済みで無害化されたデータのみがモデルに影響を与えることを保証し、偶発的なエラーと意図的なデータ汚染攻撃の両方によるリスクを軽減します。
- **データ ソース (SAIF #18)**<sup>（注）</sup>: AI システムのデータは、社内運用データベース、ユーザー生成の入力、IoT センサー、またはサードパーティー プロバイダーから取得される場合があります。内部ソースは組織のポリシーによって管理され、アクセス異常が監視されます。
- **外部データ ソース (SAIF #19)**: これらのソースには、購入した市場データやパブリック API など、品質、ライセンス コンプライアンス、セキュリティに関する追加審査が必要な外部データ フィードが含まれる場合があります。組織は、これらの外部接続を保護するために、契約および技術上の管理（暗号化チャネル、相互認証など）を実施し、フィードの健全性と完全性を継続的に監査します。

----------------------------------
<div style="font-size: small">

- 注: SAIF アーキテクチャにおける SAIF #4（アプリケーション）から SAIF #18（内部データ ソース）への点線矢印はフィードバック ループを表しています。このループでは、ユーザー入力、インタラクション ログ、モデル出力など、アプリケーション実行時に生成されるデータが内部的に捕捉され、保存されます。このデータは、後でモデルの微調整や再学習に使用できます。

</div>

# 2.1. AI 脅威の特定

本書では、AI 対応アプリケーションを対象とした、アーキテクチャに基づいた高レベルなスコープ指定型脅威モデリング手法を提示します。特に、本番環境への導入が間近に迫っているシステムに焦点を当てています。私たちの目標は、QA やステージングといった管理された環境で検証可能な脅威を、導入前のペネトレーション テストと同様のスコープで厳密に分析することです。

この脅威モデルは、Google の [Secure AI Framework (SAIF)](https://saif.google/secure-ai-framework/components) で定義されたコンポーネントを中心に構築されており、脅威によって直接的および間接的に影響を受ける脅威という観点から、包括的なリスク駆動型アプローチを実現します。このアプローチには、公開されているコンポーネントだけでなく、既知または想定される脆弱性（CWE）を持つ可能性のある脆弱なコンポーネントも含まれます。脅威モデリングに基づく脆弱性テストを実行する際には、脅威によって直接的および間接的に影響を受けるコンポーネントと脆弱なコンポーネントという概念が、これらの脅威を特定のテストにマッピングするのに役立ちます。

アーキテクチャのどのコンポーネントが特定の脅威にさらされているかを特定することで、セキュリティ チームはそれらのコンポーネントを優先順位付けして評価できます。初期のテストには、潜在的に脆弱なコンポーネントの構成検証と脆弱性スキャンが含まれる場合があります。一方、後期の評価では、脅威シナリオで特定のコンポーネントを標的とする敵対的攻撃シミュレーションが行われる場合があります。敵対的脅威分析をサポートするために、[OWASP Top 10 for Large Language Models (LLMs)](https://owasp.org/www-project-top-10-for-large-language-model-applications/)<sup>[3]</sup> や [OWASP AI Exchange](https://owasp.org/www-project-ai-exchange/)<sup>[5]</sup>  などの OWASP の AI 固有の脅威分類法、および [MITRE ATLAS](https://atlas.mitre.org/)<sup>[11]</sup>などのフレームワークの戦術と手法を組み込んでいます。生成 AI の脅威テストが進化し続けるにつれ、特に異なる脅威クラスに対処するための新しいツールや技術が登場するにつれて、分類法が時間の経過とともに専門化するのは当然のことです。例えば、プロンプト インジェクション (PJI) の場合、[Pangea](https://pangea.cloud/securebydesign/aiapp-pi-taxonomy)<sup>[23]</sup> が開発しているような、よりきめ細かい分類法や分類法は、攻撃が発生する場所と方法（直接インジェクションと間接インジェクションなど）をさらに明確にするのに役立ち、プロンプト インジェクション (PIJ) 脅威のような特定の LLM 脅威に対する、より標的を絞ったテスト戦略をサポートします。このガイドは、現実的な敵対者モデリングのための構造化された基盤を確立し、AI 固有の脅威分類法（プロンプト インジェクションなどの分類法）を組み込み、テスト範囲に含めるべき攻撃パスのシミュレーションを可能にすることで、AI テストに対する包括的で脅威主導型のアプローチを提供することを目指しています。

私たちの文脈において、包括的な AI 脅威モデルは、AI ライフサイクルの最終段階、具体的には本番環境デプロイ前の QA およびステージング環境、そして既に本番環境で運用されている AI システムのベースライン評価における脅威の特定と評価に重点を置いています。このモデルは、AI パイプラインと統合全体にわたる高レベルの攻撃対象領域分析を実行し、特定された弱点を現実的かつテスト可能な脅威ベクトルに結び付ける脆弱性マッピングを実行することで、セキュリティ保証の基盤として機能します。脅威は、その悪用可能性と潜在的なビジネスへの影響に基づいて優先順位付けされ、最も重要なリスクに重点が置かれます。このモデルには、既存の技術、アーキテクチャ、および手順の管理の評価も含まれており、セキュリティ ギャップを浮き彫りにし、実用的な軽減策を提案します。重要なことは、すべての脅威モデリングの出力が、NIST AI RMF や GDPR などのビジネス目標とコンプライアンス要件にマッピングされ、組織の目標と規制要件との整合性が確保されることです。

## 事業影響度分析 (BIA)

PASTA (Process for Attack Simulation and Threat Analysis) 脅威モデリング手法に基づき、OWASP のアプローチは、セキュリティ分析とビジネス目標を整合させ、リスクの観点からビジネスへの影響を判断することから始まります。これにより、脅威モデリングの取り組みが現実世界における影響と組織の優先事項に根ざしたものになります。

Secure AI Framework (SAIF) は、AI ライフサイクル全体にわたる複数の技術的リスクとシステム的リスクを概説しています。これらのリスクのうち、どれがビジネスに大きな影響を与えるかを評価するために、財務損失、ブランド評判、法令遵守、業務継続性、顧客信頼といった主要な組織的側面への潜在的な影響を検証します。

表 1.1 では、SAIF に記載されている AI リスクを示しています。各リスク カテゴリとその説明、評価されたビジネスへの影響、発生可能性と影響に基づく対応するリスク レベル、および SAIF で特徴付けられるリスク所有者とともに示しています。モデル作成者は「自身または他者が使用するために AI モデルを学習または開発する者」、モデル消費者（訳注: ＝モデル利用者？）は「AI モデルを使用して AI を活用した製品やアプリケーションを構築する者」と定義されます。適切なリスク所有者は、管理策が適用される場所に基づきます (つまり、アプリケーション/モデル = モデル利用者、データ/インフラストラクチャ = モデル作成者、両方 = モデル作成者、モデル利用者)。

<div align="center">

表 1.1:  AI リスク（SAIF 一覧）と事業影響度

| リスク | 解説 | 事業影響度 | リスク レベル<br>（可能性✕影響度）<sup>（注）</sup> | リスク所有者 |
| ----- | ----- | ----- | ----- | ----- |
| データ汚染 | 攻撃者は、悪意のあるデータを挿入して、モデルの動作に影響を与えたり、パフォーマンスを低下させたりします。| モデルの不安定性、不正確な出力、パフォーマンスの低下、コンプライアンス違反の可能性。| 🔴 重大<br>（高×高） | モデル作成者 |
| 不正な学習データ |学習中に承認されていないデータセットや完全性の低いデータセットを使用すると、バイアスやバックドアが生じます。 | モデルのバイアス、信頼できない予測、法的/規制上のリスク。 | 🔴 重大<br>（高×高） | モデル作成者 |
| モデルのソース改ざん | モデル ファイルが、保存、取得、またはバージョン管理中に改変されます。 | モデルの動作の侵害、データ漏洩、サプライ チェーンの侵害。 | 🔴 重大<br>（高×高） | モデル作成者 |
| 過剰なデータ処理 | 処理中に過剰または不要なデータが意図せず公開されます。 | データ最小化ポリシー違反、潜在的なプライバシー侵害。 | 🟠 高<br>（中×高） | モデル作成者 |
| モデルの持ち出し | モデルの重み、アーキテクチャ、またはエンベディングの盗難。| 知的財産の損失、モデルの悪用、攻撃者による収益化。 | 🔴 重大<br>（高×高） | モデル作成者 |
| モデルのデプロイメント時改ざん | 攻撃者は、デプロイメント中にモデルの構成またはルーティングを操作します。 | モデルの不正な動作、機密クエリの誤ったルーティング。  | 🔴 重大<br>（高×高） | モデル作成者 |
| ML サービスの運用妨害 | モデル層に過負荷をかけ、サービスを低下させたり拒否状態にされたりします。 | ダウン タイム、ユーザー エクスペリエンスの低下、潜在的な SLA 違反。 | 🟠 高<br>（高×中） | モデル利用者 |
| モデルのリバース エンジニアリング | モデル ロジックを抽出するために、過剰なクエリまたはプローブが使用されます。 | モデルの IP（知的財産）損失、間接的なデータ漏洩、不正な複製。| 🟠 高<br>（高×中） | モデル利用者 |
| セキュアでない統合コンポーネント | セキュリティ上の欠陥があるプラグイン/ツールはモデルの動作に影響を与えます。 | 攻撃対象領域の拡大、プラグインの悪用、不正アクセス。| 🟠 高<br>（中×高） | モデル利用者 |
| プロンプト インジェクション | 埋め込まれた指示を通じてモデルの動作を変更するようにプロンプトが操作されます。 | データ漏洩、管理策の迂回、幻覚コンテンツ、コンプライアンス リスク。 | 🔴 重大<br>（高×高） | モデル作成者、モデル利用者 |
| モデルの回避 | 細工された入力はモデルによる検出または制御を迂回します。 | 分類または検出ロジックの回避。 | 🟠 高<br>（中×高） | モデル作成者、モデル利用者 |
| 機密情報の開示 | 出力によって、意図せず個人情報や学習データが公開される可能性があります。| コンプライアンス違反（GDPR など）、評判の失墜。| 🔴 重大<br>（高×高） | モデル作成者、モデル利用者 |
| 機密情報の推測 | 攻撃者は、繰り返しクエリを実行してプライベート データを推測します。| 個人情報や規制対象情報のステルス漏洩。| 🟠 高<br>（中×高） | モデル作成者、モデル利用者 |
| セキュアでないモデル出力 | モデル出力には、安全でない、有害な、またはポリシーに違反するコンテンツが含まれる場合があります。| ユーザーへの危害、ブランドの信頼の低下、法的責任。| 🟠 高<br>（中×高） | モデル利用者 |
| 不正なアクション | モデルによってトリガーされるプラグイン/ツールが、安全でない操作または意図しない操作を実行します。| 意図しないアクション、データの持ち出し、または権限の昇格。| 🔴 重大<br>（高×高） | モデル利用者 |

</div>

この段階でビジネスへの影響を分析することで、脅威モデルは最も重要な AI リスクに焦点を当て、管理策のテストを組織の優先事項と整合させることができます。事業が主に AI モデルの利用者、作成者、あるいはその両方であるかによって、リスク軽減の責任が決定されます。各組織は、固有の使用事例、機能的依存関係、そして露出データの機密性によって形成される独自の AI リスク プロファイルを持っているため、この整合により、脅威モデリングと AI テストの取り組みは、ビジネスにとって最も重要なものを保護するためにカスタマイズされます。最終的に、SAIF リスクをビジネスへの影響にマッピングすることは、脅威の優先順位付けと効果的な軽減戦略の策定に不可欠です。

----------------------------------
<div style="font-size: small">

- AI リスク評価アプローチに関する注記: 検索拡張生成（RAG）、微調整された LLM、マルチ エージェント システムといった特定の AI の種類の実装に伴う固有のリスクと、これらのシステムの統合、デプロイメント、保護方法を悪用した攻撃への露出との間には、重要な区別があります。例えば、プロンプト インジェクション、セキュアでない RAG チェーン、API 鍵の漏洩といったリスクは、多くの場合、モデル アーキテクチャ自体ではなく、周囲のアプリケーション ロジックやシステム設計の脆弱性に起因します。この区別は、データ汚染が、現在デプロイ済みの ML システムでは稀であるにもかかわらず、発生確率と影響度が高いと評価される理由も説明しています。データ汚染は、モデルの動作に長期的な影響を与え、その検知や復旧の難しさから、その深刻度は正当化されます。一方、マルチターン プロンプトによる機密データの露出は、より一般的ではあるものの、部分的な軽減策（出力フィルタリング、コンテキスト制限など）や、一部の環境ではシステムへの影響が低いため、中程度の評価となる場合があります。 AI 固有の脅威、特に既知の脆弱性に関連する脅威の発生可能性と影響度をより確実に評価するには、構造化されたリスク評価手法が必要です。[OWASP AI Vulnerability Scoring System (AIVSS)](https://aivss.owasp.org/) は、有望な基盤を提供します。AIVSS は、悪用可能性、予測可能性、影響の深刻度、軽減策の範囲といった要素を組み込んでおり、AI 駆動型システムにおける脅威の評価に特化しています。AI の脅威環境が進化するにつれ、AIVSS のような標準化されたスコアリング フレームワークは、正確かつ実用的なリスクの優先順位付けに不可欠となるでしょう。

</div>

## 情報セキュリティ リスクに対する CIA ベースの脅威分析

脅威分析段階に移り、対象資産の機密性、完全性、可用性 (CIA) への潜在的な影響に焦点を当てた、初期の高レベル脅威分析を実施する必要があります。これらの資産は、以前に対象範囲を定めた SAIF コンポーネントによって定義されるため、システムの重要な要素に関連する脅威情勢について、一貫性のある階層的な理解が得られます。

脅威モデリング プロセスの一環として、SAIF の各層（データ、モデル、アプリケーション、インフラストラクチャ）をCIA トライアドの観点から分析し、脅威がシステムのセキュリティ目標をどのように侵害するかを評価しました。この分解により、AI システムのアーキテクチャと相互作用に固有の脆弱性を攻撃者がどのように悪用するかをより深く理解することができます<sup>（注）</sup>。

### 機密性に関わる脅威

機密性の侵害とは、機密データ、モデル、または通信への不正アクセスまたは開示を指します。SAIF コンポーネント全体で、以下の脅威ベクトルを特定しました。

- **中間者 (MITM) 攻撃**: RAG パイプラインの取得側と生成側、またはモデル API エンドポイントとユーザー インターフェース間など、AI コンポーネント間のセキュリティ保護されていない通信を標的とします。
- **データの傍受**: 転送中または保存中のユーザー入力、モデル出力、または外部取得ソース（例: ベクトル データベース）の不正に捕捉します。
- **機密モデルまたは独自モデルの意図せぬ公開**: 機密性の高い学習データまたは知的財産を推測するために、モデルの動作をリバース エンジニアリングまたは監視します。

影響を受ける SAIF コンポーネントには、入出力フローと外部取得ソースを含むデータ、レスポンス生成の機構と内部重みによって脆弱なモデル（抽出攻撃の標的となる可能性があります）、および適切にセキュアになっていない場合に悪用される可能性のある通信チャネルと公開された API エンドポイントを含むインフラストラクチャが含まれます。

### 完全性に関わる脅威

完全性に関わる脅威は、システム動作の正確性と信頼性に影響を与えるデータまたはコマンドの不正な変更またはインジェクションに焦点を当てています。特定されている脅威ベクトルには以下が含まれます。

- **データ インジェクションまたはリプレイ攻撃**: 攻撃者は、操作された入力を挿入したり、有効なリクエストをリプレイしたりすることで、モデルの動作を歪めたり、悪意のある出力を再学習させたりする可能性があります。
- **なりすましと API 偽装**: 攻撃者は、信頼できるサービス（プラグイン、サードパーティーのデータソースなど）を偽装してシステムを欺いたり、偽の入力を提供したりする可能性があります。
- **敵対的入力インジェクション**: モデル出力を予期しない方法（敵対的サンプルやプロンプト インジェクションなど）で変更するように特別に設計された入力を作成します。

影響を受ける SAIF コンポーネントには、データ（特に前処理パイプラインとリトリーバー出力）、モデル（入力層とプロンプト処理チェーン経由）、アプリケーション（プラグイン インターフェースとオーケストレーション ロジック経由）、そしてインフラストラクチャ（システム全体をサポートする API ゲートウェイとサービス間通信を含む）が含まれます。

### 可用性に関わる脅威

可用性に関するリスクによって、AI サービスまたはコンポーネントへのアクセスが低下、中断、または拒否状態になるする恐れがあります。このカテゴリの脅威ベクトルには、以下が含まれます。
- **リソース枯渇攻撃**: 推論エンドポイントまたはベクトル検索 API に大量のクエリを過負荷状態にし、サービス運用妨害　（DoS) を引き起こします。
- **外部依存関係での障害**: クラウド ベースのコンポーネント（外部ベクトル DBやモデル API など）のダウン タイムにより、パイプラインに連鎖的な障害が発生します。
- **レイテンシ攻撃**: Slowloris（低速 HTTP リクエスト）などの手法で、モデルを提供するインフラストラクチャの応答性を標的とし、システムの可用性を低下させます。

影響を受ける SAIF コンポーネントには、インフラストラクチャ（具体的にはシステムの可用性を支えるホスティング層とネットワーク ゲートウェイ）、モデル（特にリソース ベース攻撃の標的となる可能性のある推論エンドポイント）、そしてアプリケーション（オーケストレーション層と依存関係処理ロジックを介して、ストレスや外部からの中断時に障害点となる可能性がある）が含まれます。
<br><br>
以降では、CIA 脅威と、対象範囲に含まれる AI アーキテクチャの SAIF コンポーネントのマッピングを示します。

----------------------------------
<div style="font-size: small">

- *注: 重要なことは、CIA 脅威分類が AI に重点を置いたセキュリティ対策に既に効果的に適用されている点です。例えば、[OWASP AI Exchange の AI セキュリティ マトリックス](https://owaspai.org/docs/ai_security_overview/#ai-security-matrix)<sup>[5]</sup>では、AI リスクを AI セキュリティ マトリックスの CIA カテゴリにマッピングしています。この前例は、新興 AI システムにおける脅威の特定と伝達の出発点としての CIA の実用性と移転可能性を裏付けています。*

</div>

## CIA 脅威の AI アーキテクチャ層および AI コンポーネントへのマッピング

以下の表は、AI システム アーキテクチャの各コンポーネントに対する機密性、完全性、可用性 (CIA) の脅威のマッピングを、SAIF (Secure AI Framework) 層<sup>（注）</sup>ごとにまとめたものです。各表は、アプリケーション、モデル、インフラストラクチャ、データの 4 つの既定の層のいずれかに対応し、個々のコンポーネントと、脅威モデリング演習で特定された具体的な脅威を一覧化しています。この階層構造により、AI ライフサイクル全体にわたるセキュリティ リスクの構造化された評価が可能になり、アーキテクチャの境界に沿った軽減策の優先順位付けが可能になります。

<div align="center">

表 1.2:  SAIF アプリケーション層と CIA 脅威のマッピング

| SAIF コンポーネント |  対応する CIA 脅威 | 
| ----- | ----- |
| #1 ユーザー | <ul><li>機密性: ユーザー入力の漏洩<li>完全性: 偽装されたユーザー ID<li>可用性: ユーザーのロックアウトまたは入力送信の拒否</ul> |
| #2 ユーザー入力 | <ul><li>機密性: 機密性の高いクエリ<li>完全性: 入力のインジェクションまたは操作<li>可用性: ユーザー入力のブロックまたはレート制限</ul> |
| #3 ユーザー出力 | <ul><li>機密性:出力の漏洩<li>完全性: 出力の操作<li>可用性: ユーザー出力のブロックまたはレート制限</ul> |
| #4 アプリケーション | <ul><li>機密性: アプリケーションの記憶やロジックの漏洩<li>完全性: ビジネス ロジックの改ざん<li>可用性: アプリケーションのクラッシュや応答不能</ul> |
| #5 エージェント/プラグイン | <ul><li>機密性: プラグインのデータやロジックへの不正アクセス<li>完全性: 詐称・操作されたプラグイン動作<li>可用性: プラグインの障害や利用不可</ul> |
| #6 外部ソース | <ul><li>機密性: 外部データの傍受<li>完全性: 汚染または改ざんされたサードパーティー コンテンツ<li>可用性: 外部サービスのダウン タイムまたはスロットリング</ul> |


表 1.3:  SAIF モデル層と CIA 脅威のマッピング

| SAIF コンポーネント |  対応する CIA 脅威 | 
| ----- | ----- |
| #7 入力の処理 | <ul><li>機密性: モデルの重みまたはメタデータの盗難<li>完全性: 入力検証の迂回<li>可用性: 前処理のボトルネックまたは応答不能</ul> |
| #8 出力の処理 | <ul><li>機密性: モデル応答の漏洩<li>完全性: 出力の操作またはフィルタリングの迂回<li>可用性: 応答の遅延またはブロック</ul> |
| #9 モデルの利用 | <ul><li>機密性: 推論結果の意図せぬ公開<li>完全性: モデル ポリシーの回避<li>可用性: 推論の失敗または過負荷</ul> |

表 1.4:  SAIF インフラストラクチャ層と CIA 脅威のマッピング

| SAIF コンポーネント |  対応する CIA 脅威 | 
| ----- | ----- |
| #10 モデル ストレージ インフラストラクチャ | <ul><li>機密性: 入力前処理ロジックの意図せぬ公開<li>完全性: 改ざんされたモデル アーティファクト<li>可用性: リポジトリへのアクセス不能</ul> |
| #11 モデル サービング インフラストラクチャ | <ul><li>機密性: 意図せず公開されたエンドポイントまたは推論テレメトリ<li>完全性: 不正な入力の実行<li>可用性: サービス エンドポイントの応答不能</ul> |
| #12 モデル評価 | <ul><li>機密性: 評価指標またはテスト データの開示<li>完全性: 改ざんされた結果<li>可用性: 評価プロセスの応答不能または過負荷</ul> |
| #13 モデルの学習＆調整 | <ul><li>機密性: 学習データセットの漏洩<li>完全性: データ汚染またはパラメータ改ざん<li>可用性: パイプラインの障害または計算資源不足</ul> |
| #14 モデル フレームワーク＆コード | <ul><li>機密性: ソースコードやライブラリの意図せぬ公開<li>完全性: 依存関係のインジェクションやコード改ざん<li>可用性: ビルド時や実行時のエラー</ul> |
| #15 データ ストレージ インフラストラクチャ | <ul><li>機密性: 保存されたデータへの不正アクセス<li>完全性: スキーマやレコードの操作<li>可用性: ストレージ アクセスの失敗</ul> |

表 1.5:  SAIF データ層と CIA 脅威のマッピング

| SAIF コンポーネント |  対応する CIA 脅威 | 
| ----- | ----- |
| #16 学習データ | <ul><li>機密性: 機密性の高い学習例の漏洩<li>完全性: 学習レコードの汚染または重複<li>可用性: データセットの破損または喪失</ul> |
| #17 データのフィルタリング＆処理 | <ul><li>機密性: 中間データ状態の意図せぬ公開<li>完全性: 悪意のある変換ロジック<li>可用性: データ パイプラインの障害</ul> |
| #18 内部データ ソース | <ul><li>機密性: 内部データベースへのアクセス<li>完全性: 偽造されたレコードの挿入<li>可用性: バックエンド システムの利用不可</ul> |
| #19 外部データ ソース | <ul><li>機密性: 外部フィードの盗聴<li>完全性: 誤情報または古いデータ<li>可用性: ソースの利用不可または API の不正使用</ul> |

</div>

CIA トライアドはセキュリティ脅威を特定するための基本的なレンズとして依然として機能していますが、現代の AI システムのリスク情勢全体を捉えるには、もはやそれだけでは不十分です。AI は、固有の攻撃対象領域、信頼境界、そしてシステム的な動作をもたらし、より広範な脅威モデリング アプローチを必要とします。以下のセクションでは、既存の方法論を強化するだけでなく、AI の文脈において包括的かつ目的に適合していることを確実にするために、2 部構成の分析を実施します。

1. **AI 固有のセキュリティ脅威**: OWASP AI Exchange プロジェクトと OWASP GenAI プロジェクトによって公開された脅威カテゴリをレビューし、既存の方法論と照らし合わせて、組み込むべき AI 固有のセキュリティ脅威を特定します。
2. **信頼でき責任ある AI に関する考慮事項**: 信頼でき責任ある AI というレンズを通して AI システムのアーキテクチャを評価し、AI の開発とデプロイ中に生じる可能性のある倫理、公平性、説明責任、ガバナンスに関する懸念に関連するセキュリティ以外の脅威の特定に重点を置きます。

この統合分析により、従来のセキュリティ リスクと、より広範な責任ある AI の側面の両方にわたって脅威の範囲を絞り込むことができます。

----------------------------------
<div style="font-size: small">

- *注: CIA トライアドへの脅威のマッピングは、SAIF コンポーネント全体の機密性、整合性、可用性のリスクに関する基礎的な理解を提供しますが、AI システムにとってレジリエンス（回復力）が同様に重要であることを認識することが重要です。CIA をさらに発展させるために、補完的な視点として DIE トライアド（Distributed, Immutable, Ephemeral; 分散型、不変型、一時的）<sup>[20]</sup>を導入します。DIE は、動的で大規模かつ継続的に進化する AI システムに不可欠な、アーキテクチャの堅牢性と運用上の存続可能性を重視しています。DIE 脅威の SAIF コンポーネントへのマッピングは付録 B に記載されています。CIA と DIE の両方を適用することで、AI コンポーネントがセキュアであるだけでなく、設計段階からレジリエンスを備えていることを保証できます。*

</div>

## 2.1.1. OWASP 脅威のアーキテクチャ マッピング

本章では、OWASP Top 10 LLM Risks (2025) および OWASP AI Exchange Threats における AI セキュリティ脅威を、Google の Secure AI Framework (SAIF) を基盤とするモジュール型 AI システム アーキテクチャに構造的にマッピングします。

AI アーキテクチャをデータ、インフラストラクチャ、モデル、アプリケーションという 4 つのコア レイヤーにわたって調査することで、脅威がリスク露出として顕在化する可能性が最も高い箇所を視覚的に特定し、集中的かつ効果的なセキュリティ テストを実施できます。図 2 はこの対応関係を示しており、AI システム内の特定のコンポーネントに脅威をマッピングするための参考資料として役立ちます。

<div align="center">

![](./assets/SAIF_Threat_Model_Diagram.png)

図 2: OWASP 脅威（LLM Top 10 および AI Exchange）の脅威モデルの SAIF ベースライン アーキテクチャの影響を受けるAI コンポーネントへのマッピング
</div>

潜在的な脅威を特定し AI システムのアーキテクチャと運用コンテキストを分析するために、構造化されたプロセスを採用しています。このアプローチでは、OWASP が定義する脅威カテゴリ、特に *OWASP Top 10 for LLM* および*OWASP AI Exchange* を参照し、プロンプト インジェクション、データ汚染、モデル回避などのリスクを特定します。特定された脅威ごとに、代表的な脅威シナリオを概説し、影響を受けるシステム コンポーネントを明らかにします。このマッピングは、悪用可能な脆弱性や弱点を発見するための、的を絞ったテスト ケースを導き出すのに役立ちます。

明確さと一貫性を保つため、Google の SAIF リスク ラベルと同様に、OWASP AI 脅威には特定の頭字語を割り当てています。例えば、プロンプト インジェクションの脅威は (PIJ)、データおよびモデルの汚染の脅威は (DMP) というラベルが付けられています。各脅威は、OWASP LLM 脅威ラベル（例: *LLM01*、*LLM02*）や OWASP AI Exchange ラベル（例: *脅威 2.1 - 回避*）といった、対応する既知の OWASP ラベル識別子にもマッピングされています。この二重マッピングにより、各脅威が正式に文書化されている OWASP プロジェクトの関連セクションへの追跡可能性が確保されます。

各脅威について、影響を受けるアーキテクチャ コンポーネントと、検討中の脅威シナリオに対する各コンポーネントの脆弱性を検証するためのテスト戦略を明確に示した脅威シナリオの例を提供します<sup>（注）</sup>。

----------------------------------
<div style="font-size: small">

- 注: *AI システムの標的型攻撃に対する耐性を評価し、一連の特定のテストを実行する際には、複数の脅威シナリオが関連する場合があります。ここで提示するテスト シナリオは、高レベルのセキュリティ テスト開発をサポートするための実例として役立ちます。OWASP Top 10 LLM および AI Exchange の脅威それぞれに対するより詳細な脅威モデルは、AI デプロイメント固有のデータフロー、技術スタック、モデルの動作、そして開発とデプロイメントを支えるインフラストラクチャを考慮する必要があります。脅威モデルには、MITRE ATT&CK などの構造化フレームワークも組み込む必要があります。これにより、攻撃ベクトルの正確なマッピングが可能になり、PASTA 脅威モデリング手法の攻撃モデリングおよび脆弱性分析の段階で扱われているように、現実世界の悪用手法に沿った特定の敵対的テストをサポートできます。*

</div>

## 2.1.2. AI システムの RAI 脅威の特定

### 責任ある AI のみ

### AI アプリケーションの RAI 脅威

### AI モデルの RAI 脅威

### AI インフラストラクチャの RAI 脅威

### AI データの RAI 脅威

### AI テストの 4 つの柱

#### 1. AI アプリケーションのテスト

#### 2. AI モデルのテスト

#### 3. AI インフラストラクチャのテスト

#### 4. AI データのテスト
